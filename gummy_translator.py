import os
import queue
import threading
import time
import subprocess
import json
import tempfile

import dashscope
import pyaudio
import wx
import wx.richtext as rt
from dashscope.audio.asr import *
from dashscope.audio.tts_v2 import *

import requests
import ctypes  # å¯¼å…¥ ctypes åº“

# å°è¯•å¯¼å…¥sounddeviceä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ
try:
    import sounddevice as sd
    import numpy as np
    SOUNDDEVICE_AVAILABLE = True
except ImportError:
    SOUNDDEVICE_AVAILABLE = False

# Add a global variable to control TTS
enable_tts = False

# Add a global variable to control API calls
enable_api_calls = True  # é»˜è®¤å¯ç”¨APIè°ƒç”¨

# Add a global variable to control listening/pause
listening_paused = False  # é»˜è®¤ä¸æš‚åœç›‘å¬

# Add a global variable to track translator status
translator_stopped = False  # è·Ÿè¸ªtranslatorçŠ¶æ€
need_restart_translator = False  # æ ‡è®°æ˜¯å¦éœ€è¦é‡å¯translator

# Add global variables for audio source control
audio_source = 'system'  # 'microphone' or 'system' - é»˜è®¤ä½¿ç”¨ç³»ç»ŸéŸ³é¢‘
current_system_device = None  # å½“å‰é€‰æ‹©çš„ç³»ç»ŸéŸ³é¢‘è®¾å¤‡
ffmpeg_process = None  # FFmpegè¿›ç¨‹
system_audio_queue = queue.Queue()  # ç³»ç»ŸéŸ³é¢‘æ•°æ®é˜Ÿåˆ—
sounddevice_stream = None  # sounddeviceæµå¯¹è±¡
ffmpeg_path = None  # è‡ªå®šä¹‰FFmpegè·¯å¾„

# é…ç½®æ–‡ä»¶è·¯å¾„
CONFIG_FILE = 'gummy_translator_config.json'

# é»˜è®¤é…ç½®
DEFAULT_CONFIG = {
    'audio_source': 'system',
    'ffmpeg_path': None,
    'dashscope_api_key': '<your-dashscope-api-key>',
    'siliconflow_api_key': '<your-SiliconFlow-api-key>',
    'target_language': 'zh',
    'tts_voice': 'FunAudioLLM/CosyVoice2-0.5B:alex',
    'current_system_device': None,
    'enable_tts': False,
    'asr_model': 'gummy-realtime-v1',  # é»˜è®¤ASRæ¨¡å‹
    'api': {
        'enabled': True  # é»˜è®¤å¯ç”¨APIè°ƒç”¨
    }
}

# å…¨å±€é…ç½®
config = DEFAULT_CONFIG.copy()

def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    global config, audio_source, ffmpeg_path, target_language, current_system_device, enable_tts, enable_api_calls
    
    try:
        if os.path.exists(CONFIG_FILE):
            with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
                saved_config = json.load(f)
                config.update(saved_config)
                print(f"å·²åŠ è½½é…ç½®æ–‡ä»¶: {CONFIG_FILE}")
        else:
            print("æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
    except Exception as e:
        print(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        config = DEFAULT_CONFIG.copy()
    
    # åº”ç”¨é…ç½®åˆ°å…¨å±€å˜é‡
    audio_source = config.get('audio_source', 'system')
    ffmpeg_path = config.get('ffmpeg_path', None)
    target_language = config.get('target_language', 'zh')
    current_system_device = config.get('current_system_device', None)
    enable_tts = config.get('enable_tts', False)
    enable_api_calls = config.get('api', {}).get('enabled', True)

def save_config():
    """ä¿å­˜é…ç½®æ–‡ä»¶"""
    global config, enable_api_calls
    
    # æ›´æ–°é…ç½®
    config['audio_source'] = audio_source
    config['ffmpeg_path'] = ffmpeg_path
    config['target_language'] = target_language
    config['current_system_device'] = current_system_device
    config['enable_tts'] = enable_tts
    # asr_modelä¼šåœ¨è®¾ç½®å¯¹è¯æ¡†ä¸­æ›´æ–°ï¼Œè¿™é‡Œä¸éœ€è¦ä¿®æ”¹
    
    # ç¡®ä¿apié…ç½®å­˜åœ¨
    if 'api' not in config:
        config['api'] = {}
    config['api']['enabled'] = enable_api_calls
    
    try:
        with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        print(f"é…ç½®å·²ä¿å­˜åˆ°: {CONFIG_FILE}")
    except Exception as e:
        print(f"ä¿å­˜é…ç½®æ–‡ä»¶å¤±è´¥: {e}")

# Set your Dashscope API key
def init_dashscope_api_key():
    """
        Set your DashScope API-key. More information:
        https://github.com/aliyun/alibabacloud-bailian-speech-demo/blob/master/PREREQUISITES.md
    """
    global config
    
    if 'DASHSCOPE_API_KEY' in os.environ:
        dashscope.api_key = os.environ['DASHSCOPE_API_KEY']
        config['dashscope_api_key'] = os.environ['DASHSCOPE_API_KEY']
    elif config.get('dashscope_api_key') and config['dashscope_api_key'] != '<your-dashscope-api-key>':
        dashscope.api_key = config['dashscope_api_key']
    else:
        dashscope.api_key = '<your-dashscope-api-key>'  # set API-key manually

# Set the target language for translation
target_language = 'zh'

# Function to check if FFmpeg is available
def check_ffmpeg():
    """æ£€æŸ¥FFmpegæ˜¯å¦å¯ç”¨"""
    global ffmpeg_path, config
    
    # å¦‚æœé…ç½®ä¸­æœ‰è‡ªå®šä¹‰è·¯å¾„ï¼Œä¼˜å…ˆä½¿ç”¨
    if config.get('ffmpeg_path') and os.path.exists(config['ffmpeg_path']):
        try:
            result = subprocess.run([config['ffmpeg_path'], '-version'], 
                                  capture_output=True, text=True, timeout=5)
            if result.returncode == 0:
                ffmpeg_path = config['ffmpeg_path']
                print(f"ä½¿ç”¨é…ç½®ä¸­çš„FFmpeg: {ffmpeg_path}")
                return True
        except (subprocess.TimeoutExpired, FileNotFoundError):
            print(f"é…ç½®ä¸­çš„FFmpegè·¯å¾„æ— æ•ˆ: {config['ffmpeg_path']}")
    
    # é¦–å…ˆå°è¯•ç³»ç»ŸPATHä¸­çš„ffmpeg
    try:
        result = subprocess.run(['ffmpeg', '-version'], 
                              capture_output=True, text=True, timeout=5)
        if result.returncode == 0:
            ffmpeg_path = 'ffmpeg'  # ä½¿ç”¨ç³»ç»ŸPATHä¸­çš„ffmpeg
            return True
    except (subprocess.TimeoutExpired, FileNotFoundError):
        pass
    
    # å¦‚æœç³»ç»ŸPATHä¸­æ‰¾ä¸åˆ°ï¼Œå°è¯•å¸¸è§çš„å®‰è£…è·¯å¾„
    common_paths = [
        r'C:\Users\9t\ffmpeg-7.1.1-essentials_build\bin\ffmpeg.exe',
        r'C:\ffmpeg\bin\ffmpeg.exe',
        r'C:\Program Files\ffmpeg\bin\ffmpeg.exe',
        r'C:\Program Files (x86)\ffmpeg\bin\ffmpeg.exe'
    ]
    
    for path in common_paths:
        if os.path.exists(path):
            try:
                result = subprocess.run([path, '-version'], 
                                      capture_output=True, text=True, timeout=5)
                if result.returncode == 0:
                    ffmpeg_path = path
                    print(f"æ‰¾åˆ°FFmpeg: {path}")
                    return True
            except (subprocess.TimeoutExpired, FileNotFoundError):
                continue
    
    return False

def get_ffmpeg_command():
    """è·å–FFmpegå‘½ä»¤è·¯å¾„"""
    global ffmpeg_path
    if ffmpeg_path is None:
        check_ffmpeg()
    return ffmpeg_path or 'ffmpeg'

def test_audio_capture():
    """æµ‹è¯•éŸ³é¢‘æ•è·åŠŸèƒ½"""
    print("\n" + "=" * 60)
    print("ğŸ§ª éŸ³é¢‘æ•è·æµ‹è¯•")
    print("=" * 60)
    
    if not check_ffmpeg():
        print("âŒ FFmpegä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡Œæµ‹è¯•")
        return False
    
    print("ğŸµ å¼€å§‹æµ‹è¯•ç³»ç»ŸéŸ³é¢‘æ•è·...")
    print("è¯·åœ¨ç³»ç»Ÿä¸­æ’­æ”¾ä¸€äº›éŸ³é¢‘ï¼ˆéŸ³ä¹ã€è§†é¢‘ç­‰ï¼‰")
    print("æµ‹è¯•å°†è¿è¡Œ10ç§’é’Ÿ...")
    
    # å¯åŠ¨éŸ³é¢‘æ•è·
    success = start_ffmpeg_audio_capture()
    
    if not success:
        print("âŒ éŸ³é¢‘æ•è·å¯åŠ¨å¤±è´¥")
        return False
    
    # æµ‹è¯•10ç§’é’Ÿ
    start_time = time.time()
    data_count = 0
    
    try:
        while time.time() - start_time < 10:
            try:
                # æ£€æŸ¥æ˜¯å¦æœ‰éŸ³é¢‘æ•°æ®
                data = system_audio_queue.get(timeout=0.1)
                if data:
                    data_count += 1
                    if data_count % 10 == 0:  # æ¯ç§’æ˜¾ç¤ºä¸€æ¬¡
                        print(f"â±ï¸  å·²æ•è· {data_count} ä¸ªéŸ³é¢‘æ•°æ®åŒ…...")
            except queue.Empty:
                continue
                
    except KeyboardInterrupt:
        print("ç”¨æˆ·ä¸­æ–­æµ‹è¯•")
    
    # åœæ­¢æ•è·
    stop_ffmpeg_audio_capture()
    
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
    print(f"  æ•è·çš„æ•°æ®åŒ…æ•°é‡: {data_count}")
    
    if data_count > 0:
        print("âœ… éŸ³é¢‘æ•è·æµ‹è¯•æˆåŠŸï¼")
        print("  ç³»ç»ŸéŸ³é¢‘å¯ä»¥æ­£å¸¸æ•è·")
        return True
    else:
        print("âŒ éŸ³é¢‘æ•è·æµ‹è¯•å¤±è´¥ï¼")
        print("  å¯èƒ½çš„åŸå› :")
        print("  1. ç³»ç»Ÿæ²¡æœ‰æ’­æ”¾éŸ³é¢‘")
        print("  2. ç«‹ä½“å£°æ··éŸ³æœªå¯ç”¨")
        print("  3. éœ€è¦ä½¿ç”¨è™šæ‹ŸéŸ³é¢‘è®¾å¤‡")
        print("  4. æƒé™é—®é¢˜")
        return False

def list_all_audio_devices():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„éŸ³é¢‘è®¾å¤‡ç”¨äºè°ƒè¯•"""
    print("\n" + "=" * 60)
    print("ğŸ” æ£€æµ‹ç³»ç»ŸéŸ³é¢‘è®¾å¤‡")
    print("=" * 60)
    
    # 1. æ£€æŸ¥FFmpegè®¾å¤‡
    print("\nğŸ“º FFmpeg DirectShow è®¾å¤‡:")
    ffmpeg_devices = get_windows_audio_devices()
    if ffmpeg_devices:
        for i, device in enumerate(ffmpeg_devices):
            print(f"  {i}: {device['name']}")
    else:
        print("  æœªæ£€æµ‹åˆ°FFmpeg DirectShowè®¾å¤‡")
    
    # 2. æ£€æŸ¥PyAudioè®¾å¤‡
    print("\nğŸ¤ PyAudio è®¾å¤‡:")
    try:
        import pyaudio
        p = pyaudio.PyAudio()
        
        for i in range(p.get_device_count()):
            device_info = p.get_device_info_by_index(i)
            device_type = ""
            if device_info['maxInputChannels'] > 0:
                device_type += "è¾“å…¥ "
            if device_info['maxOutputChannels'] > 0:
                device_type += "è¾“å‡º "
            
            print(f"  {i}: {device_info['name']} ({device_type})")
        
        p.terminate()
    except Exception as e:
        print(f"  è·å–PyAudioè®¾å¤‡å¤±è´¥: {e}")
    
    # 3. æ£€æŸ¥sounddeviceè®¾å¤‡
    if SOUNDDEVICE_AVAILABLE:
        print("\nğŸ”Š Sounddevice è®¾å¤‡:")
        try:
            devices = sd.query_devices()
            for i, device in enumerate(devices):
                device_type = ""
                if device['max_input_channels'] > 0:
                    device_type += "è¾“å…¥ "
                if device['max_output_channels'] > 0:
                    device_type += "è¾“å‡º "
                print(f"  {i}: {device['name']} ({device_type})")
        except Exception as e:
            print(f"  è·å–sounddeviceè®¾å¤‡å¤±è´¥: {e}")
    else:
        print("\nğŸ”Š Sounddevice: ä¸å¯ç”¨")
    
    print("\n" + "=" * 60)

def show_audio_source_selection():
    """æ˜¾ç¤ºéŸ³é¢‘æºé€‰æ‹©å¯¹è¯æ¡†"""
    # æ£€æŸ¥FFmpegçŠ¶æ€
    ffmpeg_available = check_ffmpeg()
    ffmpeg_status = "âœ… å¯ç”¨" if ffmpeg_available else "âŒ ä¸å¯ç”¨"
    
    print()
    print("=" * 60)
    print("ğŸµ è¯·é€‰æ‹©éŸ³é¢‘è¾“å…¥æº")
    print("=" * 60)
    print()
    print("ğŸ¤ é€‰é¡¹1: éº¦å…‹é£å½•éŸ³")
    print("   - æ•è·éº¦å…‹é£è¾“å…¥çš„è¯­éŸ³")
    print("   - é€‚ç”¨äºç”¨æˆ·ç›´æ¥è¯´è¯çš„åœºæ™¯")
    print("   - ç¨³å®šå¯é ï¼Œæ— éœ€é¢å¤–é…ç½®")
    print()
    print(f"ğŸ”Š é€‰é¡¹2: ç³»ç»ŸéŸ³é¢‘ (FFmpeg: {ffmpeg_status})")
    print("   - æ•è·ç”µè„‘æ’­æ”¾çš„éŸ³é¢‘")
    print("   - é€‚ç”¨äºç¿»è¯‘è§†é¢‘ã€éŸ³ä¹ç­‰ç³»ç»Ÿå£°éŸ³")
    print("   - éœ€è¦FFmpegæˆ–è™šæ‹ŸéŸ³é¢‘è®¾å¤‡æ”¯æŒ")
    print()
    print("=" * 60)
    
    while True:
        try:
            choice = input("è¯·è¾“å…¥é€‰æ‹© (1=éº¦å…‹é£, 2=ç³»ç»ŸéŸ³é¢‘, q=é€€å‡º): ").strip().lower()
            
            if choice == 'q' or choice == 'quit':
                print("ç”¨æˆ·é€‰æ‹©é€€å‡ºç¨‹åº")
                return None
            elif choice == '1' or choice == 'mic' or choice == 'microphone':
                print("âœ… å·²é€‰æ‹©: éº¦å…‹é£å½•éŸ³")
                return 'microphone'
            elif choice == '2' or choice == 'system':
                print("âœ… å·²é€‰æ‹©: ç³»ç»ŸéŸ³é¢‘")
                
                if not ffmpeg_available:
                    print()
                    print("âš ï¸  æ³¨æ„: ç³»ç»ŸéŸ³é¢‘æ•è·éœ€è¦é¢å¤–ç»„ä»¶æ”¯æŒ")
                    print("-" * 50)
                    print("ğŸ“¦ æ–¹æ¡ˆ1: å®‰è£…FFmpeg (æ¨è)")
                    print("  â€¢ winget install FFmpeg")
                    print("  â€¢ æˆ–æ‰‹åŠ¨ä¸‹è½½: https://www.gyan.dev/ffmpeg/builds/")
                    print()
                    print("ğŸ æ–¹æ¡ˆ2: å®‰è£…Pythonåº“")
                    print("  â€¢ pip install sounddevice numpy")
                    print()
                    print("ğŸ”Œ æ–¹æ¡ˆ3: è™šæ‹ŸéŸ³é¢‘è®¾å¤‡")
                    print("  â€¢ VB-CABLE: https://vb-audio.com/Cable/")
                    print("  â€¢ VoiceMeeter: https://vb-audio.com/Voicemeeter/")
                    print("-" * 50)
                    print()
                    
                    while True:
                        confirm = input("æ˜¯å¦ç»§ç»­ä½¿ç”¨ç³»ç»ŸéŸ³é¢‘æ¨¡å¼ï¼Ÿ(y/n): ").strip().lower()
                        if confirm in ['y', 'yes', 'æ˜¯']:
                            print("ç»§ç»­ä½¿ç”¨ç³»ç»ŸéŸ³é¢‘æ¨¡å¼ï¼ˆç¨‹åºä¼šå°è¯•ä½¿ç”¨å¯ç”¨çš„å¤‡ç”¨æ–¹æ¡ˆï¼‰")
                            return 'system'
                        elif confirm in ['n', 'no', 'å¦']:
                            print("é‡æ–°é€‰æ‹©éŸ³é¢‘æº...")
                            break
                        else:
                            print("è¯·è¾“å…¥ y æˆ– n")
                else:
                    return 'system'
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1ã€2 æˆ– q")
                
        except KeyboardInterrupt:
            print("\nç”¨æˆ·ä¸­æ–­ç¨‹åº")
            return None
        except Exception as e:
            print(f"è¾“å…¥é”™è¯¯: {e}")
            print("è¯·é‡æ–°è¾“å…¥")

# Function to get Windows audio devices using FFmpeg
def get_windows_audio_devices():
    """ä½¿ç”¨FFmpegè·å–WindowséŸ³é¢‘è®¾å¤‡åˆ—è¡¨"""
    try:
        # ä½¿ç”¨FFmpegçš„dshowè¿‡æ»¤å™¨åˆ—å‡ºéŸ³é¢‘è®¾å¤‡
        cmd = [get_ffmpeg_command(), '-f', 'dshow', '-list_devices', 'true', '-i', 'dummy']
        
        # æŒ‡å®šç¼–ç ä¸ºutf-8ï¼Œé¿å…GBKç¼–ç é—®é¢˜
        result = subprocess.run(cmd, capture_output=True, text=True, 
                              encoding='utf-8', errors='ignore', timeout=10)
        
        devices = []
        
        # æ£€æŸ¥result.stderræ˜¯å¦ä¸ºNone
        if result.stderr is None:
            print("FFmpeg stderrè¾“å‡ºä¸ºç©º")
            return devices
            
        lines = result.stderr.split('\n')
        
        audio_section = False
        for line in lines:
            if '"DirectShow audio devices"' in line:
                audio_section = True
                continue
            elif '"DirectShow video devices"' in line:
                audio_section = False
                continue
            
            if audio_section and '] "' in line:
                # è§£æè®¾å¤‡åç§°
                start = line.find('] "') + 3
                end = line.find('"', start)
                if start > 2 and end > start:
                    device_name = line[start:end]
                    devices.append({
                        'name': device_name,
                        'type': 'dshow',
                        'index': len(devices)
                    })
        
        return devices
    except UnicodeDecodeError as e:
        print(f"FFmpegè¾“å‡ºç¼–ç é”™è¯¯: {e}")
        # å°è¯•ä½¿ç”¨å…¶ä»–ç¼–ç 
        try:
            result = subprocess.run(cmd, capture_output=True, 
                                  encoding='gbk', errors='ignore', timeout=10)
            if result.stderr:
                lines = result.stderr.split('\n')
                devices = []
                audio_section = False
                for line in lines:
                    if '"DirectShow audio devices"' in line:
                        audio_section = True
                        continue
                    elif '"DirectShow video devices"' in line:
                        audio_section = False
                        continue
                    
                    if audio_section and '] "' in line:
                        start = line.find('] "') + 3
                        end = line.find('"', start)
                        if start > 2 and end > start:
                            device_name = line[start:end]
                            devices.append({
                                'name': device_name,
                                'type': 'dshow',
                                'index': len(devices)
                            })
                return devices
        except Exception as fallback_e:
            print(f"ä½¿ç”¨GBKç¼–ç ä¹Ÿå¤±è´¥: {fallback_e}")
        return []
    except Exception as e:
        print(f"è·å–FFmpegéŸ³é¢‘è®¾å¤‡å¤±è´¥: {e}")
        return []

# Function to start FFmpeg system audio capture
def start_ffmpeg_audio_capture(device_name=None):
    """å¯åŠ¨FFmpegç³»ç»ŸéŸ³é¢‘æ•è·"""
    global ffmpeg_process, system_audio_queue
    
    try:
        # åœæ­¢ä¹‹å‰çš„è¿›ç¨‹
        stop_ffmpeg_audio_capture()
        
        # æ¸…ç©ºé˜Ÿåˆ—ä¸­çš„æ—§æ•°æ®
        while not system_audio_queue.empty():
            try:
                system_audio_queue.get_nowait()
            except queue.Empty:
                break
        
        # å°è¯•å¤šç§æ•è·æ–¹æ³•
        capture_methods = []
        
        # æ–¹æ³•1: WASAPI loopback (Windows é»˜è®¤éŸ³é¢‘è¾“å‡º)
        capture_methods.append({
            'name': 'WASAPIé»˜è®¤è¾“å‡ºè®¾å¤‡',
            'cmd': [
                get_ffmpeg_command(),
                '-f', 'wasapi',
                '-i', 'audio=',  # ç©ºå­—ç¬¦ä¸²è¡¨ç¤ºé»˜è®¤è®¾å¤‡
                '-acodec', 'pcm_s16le',
                '-ar', '16000',
                '-ac', '1',
                '-loglevel', 'info',  # ä¸´æ—¶æé«˜æ—¥å¿—çº§åˆ«ç”¨äºè°ƒè¯•
                '-f', 'wav',
                'pipe:1'
            ]
        })
        
        # æ–¹æ³•2: WASAPI with loopback flag
        capture_methods.append({
            'name': 'WASAPI Loopback',
            'cmd': [
                get_ffmpeg_command(),
                '-f', 'wasapi',
                '-i', 'audio=@device_cm_{33D9A762-90C8-11D0-BD43-00A0C911CE86}\\wave_{B3F8FA53-0004-438E-9003-51A46E139BEB}',
                '-acodec', 'pcm_s16le',
                '-ar', '16000',
                '-ac', '1',
                '-loglevel', 'info',
                '-f', 'wav',
                'pipe:1'
            ]
        })
        
        # æ–¹æ³•3: DirectShow Stereo Mix
        if device_name is None:
            device_name = "ç«‹ä½“å£°æ··éŸ³ (Realtek(R) Audio)"  # å¸¸è§çš„ç«‹ä½“å£°æ··éŸ³åç§°
        
        capture_methods.append({
            'name': f'DirectShow - {device_name}',
            'cmd': [
                get_ffmpeg_command(),
                '-f', 'dshow',
                '-i', f'audio={device_name}',
                '-acodec', 'pcm_s16le',
                '-ar', '16000',
                '-ac', '1',
                '-loglevel', 'info',
                '-f', 'wav',
                'pipe:1'
            ]
        })
        
        # æ–¹æ³•4: å°è¯•å…¶ä»–å¸¸è§çš„ç«‹ä½“å£°æ··éŸ³è®¾å¤‡åç§°
        common_stereo_mix_names = [
            "Stereo Mix",
            "ç«‹ä½“å£°æ··éŸ³",
            "æ··éŸ³å™¨",
            "What U Hear",
            "Wave Out Mix"
        ]
        
        for mix_name in common_stereo_mix_names:
            capture_methods.append({
                'name': f'DirectShow - {mix_name}',
                'cmd': [
                    get_ffmpeg_command(),
                    '-f', 'dshow',
                    '-i', f'audio={mix_name}',
                    '-acodec', 'pcm_s16le',
                    '-ar', '16000',
                    '-ac', '1',
                    '-loglevel', 'info',
                    '-f', 'wav',
                    'pipe:1'
                ]
            })
        
        # ä¾æ¬¡å°è¯•æ¯ç§æ–¹æ³•
        for method in capture_methods:
            print(f"å°è¯•éŸ³é¢‘æ•è·æ–¹æ³•: {method['name']}")
            try:
                ffmpeg_process = subprocess.Popen(
                    method['cmd'],
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                    bufsize=0
                )
                
                # ç­‰å¾…è¿›ç¨‹å¯åŠ¨å¹¶æ£€æŸ¥æ˜¯å¦æˆåŠŸ
                time.sleep(1.0)
                
                if ffmpeg_process.poll() is None:
                    # è¿›ç¨‹ä»åœ¨è¿è¡Œï¼Œå¯èƒ½æˆåŠŸäº†
                    print(f"âœ… {method['name']} å¯åŠ¨æˆåŠŸ")
                    break
                else:
                    # è¿›ç¨‹å·²é€€å‡ºï¼Œè·å–é”™è¯¯ä¿¡æ¯
                    stderr_output = ffmpeg_process.stderr.read().decode('utf-8', errors='ignore')
                    print(f"âŒ {method['name']} å¤±è´¥: {stderr_output[:200]}...")
                    ffmpeg_process = None
                    
            except Exception as e:
                print(f"âŒ {method['name']} å¼‚å¸¸: {e}")
                ffmpeg_process = None
        
        if ffmpeg_process is None:
            print("æ‰€æœ‰éŸ³é¢‘æ•è·æ–¹æ³•éƒ½å¤±è´¥äº†")
            return False
        
        # å¯åŠ¨çº¿ç¨‹è¯»å–éŸ³é¢‘æ•°æ®
        audio_thread = threading.Thread(target=read_ffmpeg_audio, daemon=True)
        audio_thread.start()
        
        print(f"FFmpegéŸ³é¢‘æ•è·å·²å¯åŠ¨")
        return True
        
    except Exception as e:
        print(f"å¯åŠ¨FFmpegéŸ³é¢‘æ•è·å¤±è´¥: {e}")
        return False

def read_ffmpeg_audio():
    """è¯»å–FFmpegè¾“å‡ºçš„éŸ³é¢‘æ•°æ®"""
    global ffmpeg_process, system_audio_queue
    
    if ffmpeg_process is None:
        print("FFmpegè¿›ç¨‹ä¸ºç©ºï¼Œæ— æ³•è¯»å–éŸ³é¢‘")
        return
    
    try:
        # è·³è¿‡WAVæ–‡ä»¶å¤´ï¼ˆ44å­—èŠ‚ï¼‰
        header = ffmpeg_process.stdout.read(44)
        if len(header) < 44:
            print(f"è­¦å‘Š: WAVæ–‡ä»¶å¤´ä¸å®Œæ•´ï¼Œåªè¯»å–åˆ° {len(header)} å­—èŠ‚")
            return
        
        print("å¼€å§‹è¯»å–FFmpegéŸ³é¢‘æ•°æ®...")
        audio_data_count = 0
        
        while ffmpeg_process and ffmpeg_process.poll() is None:
            # è¯»å–éŸ³é¢‘æ•°æ®å—ï¼ˆ3200å­—èŠ‚ = 16000Hz * 2å­—èŠ‚ * 0.1ç§’ï¼‰
            try:
                data = ffmpeg_process.stdout.read(3200)
                if data:
                    system_audio_queue.put(data)
                    audio_data_count += 1
                    
                    # æ¯æ”¶åˆ°100ä¸ªæ•°æ®å—æ‰“å°ä¸€æ¬¡çŠ¶æ€ï¼ˆçº¦10ç§’ï¼‰
                    if audio_data_count % 100 == 0:
                        print(f"å·²è¯»å– {audio_data_count} ä¸ªéŸ³é¢‘æ•°æ®å—ï¼Œé˜Ÿåˆ—å¤§å°: {system_audio_queue.qsize()}")
                else:
                    print("FFmpegè¾“å‡ºæµç»“æŸ")
                    break
            except Exception as read_error:
                print(f"è¯»å–éŸ³é¢‘æ•°æ®å—æ—¶å‡ºé”™: {read_error}")
                break
                
    except Exception as e:
        print(f"è¯»å–FFmpegéŸ³é¢‘æ•°æ®å‡ºé”™: {e}")
    finally:
        if ffmpeg_process:
            # è·å–é”™è¯¯è¾“å‡º
            try:
                stderr_output = ffmpeg_process.stderr.read().decode('utf-8', errors='ignore')
                if stderr_output.strip():
                    print(f"FFmpegé”™è¯¯è¾“å‡º: {stderr_output}")
            except:
                pass
        print(f"FFmpegéŸ³é¢‘è¯»å–çº¿ç¨‹ç»“æŸï¼Œæ€»å…±è¯»å–äº† {audio_data_count} ä¸ªæ•°æ®å—")

def stop_ffmpeg_audio_capture():
    """åœæ­¢FFmpegéŸ³é¢‘æ•è·"""
    global ffmpeg_process
    
    if ffmpeg_process:
        try:
            ffmpeg_process.terminate()
            ffmpeg_process.wait(timeout=3)
        except subprocess.TimeoutExpired:
            ffmpeg_process.kill()
        except Exception as e:
            print(f"åœæ­¢FFmpegè¿›ç¨‹å‡ºé”™: {e}")
        finally:
            ffmpeg_process = None

# Sounddevice backup functions
def start_sounddevice_capture():
    """ä½¿ç”¨sounddeviceæ•è·ç³»ç»ŸéŸ³é¢‘ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
    global sounddevice_stream, system_audio_queue
    
    if not SOUNDDEVICE_AVAILABLE:
        return False
    
    try:
        def audio_callback(indata, frames, time_info, status):
            """éŸ³é¢‘å›è°ƒå‡½æ•°"""
            if status:
                print(f"Sounddevice status: {status}")
            
            # è½¬æ¢numpyæ•°ç»„åˆ°bytes
            audio_data = (indata * 32767).astype(np.int16).tobytes()
            system_audio_queue.put(audio_data)
        
        # å¯åŠ¨å½•éŸ³æµ
        sounddevice_stream = sd.InputStream(
            device=current_system_device,
            channels=1,
            samplerate=16000,
            dtype=np.float32,
            blocksize=1600,  # 0.1ç§’çš„æ•°æ®å—
            callback=audio_callback
        )
        
        sounddevice_stream.start()
        print("Sounddeviceç³»ç»ŸéŸ³é¢‘æ•è·å·²å¯åŠ¨")
        return True
        
    except Exception as e:
        print(f"å¯åŠ¨sounddeviceæ•è·å¤±è´¥: {e}")
        return False

def stop_sounddevice_capture():
    """åœæ­¢sounddeviceéŸ³é¢‘æ•è·"""
    global sounddevice_stream
    
    if sounddevice_stream:
        try:
            sounddevice_stream.stop()
            sounddevice_stream.close()
        except Exception as e:
            print(f"åœæ­¢sounddeviceæµå‡ºé”™: {e}")
        finally:
            sounddevice_stream = None

def get_sounddevice_devices():
    """è·å–sounddeviceéŸ³é¢‘è®¾å¤‡åˆ—è¡¨"""
    if not SOUNDDEVICE_AVAILABLE:
        return []
    
    try:
        devices = sd.query_devices()
        device_list = []
        
        for i, device in enumerate(devices):
            if device['max_input_channels'] > 0:
                device_list.append({
                    'index': i,
                    'name': device['name'],
                    'sample_rate': int(device['default_samplerate']),
                    'type': 'sounddevice'
                })
        
        return device_list
    except Exception as e:
        print(f"è·å–sounddeviceè®¾å¤‡å¤±è´¥: {e}")
        return []

# Function to get VB-Cable or Virtual Audio Cable devices
def get_virtual_audio_devices():
    """è·å–è™šæ‹ŸéŸ³é¢‘è®¾å¤‡ï¼ˆVB-CABLE, Virtual Audio Cableç­‰ï¼‰"""
    devices = get_system_audio_devices()
    virtual_devices = []
    
    # å¸¸è§è™šæ‹ŸéŸ³é¢‘è®¾å¤‡å…³é”®è¯
    virtual_keywords = ['vb-cable', 'virtual audio cable', 'voicemeeter', 
                       'cable', 'virtual', 'vac', 'line', 'aux']
    
    for device in devices:
        if device['type'] == 'input':
            device_name_lower = device['name'].lower()
            for keyword in virtual_keywords:
                if keyword in device_name_lower:
                    virtual_devices.append(device)
                    break
    
    return virtual_devices

# Function to get available audio output devices
def get_system_audio_devices():
    """è·å–ç³»ç»ŸéŸ³é¢‘è¾“å‡ºè®¾å¤‡åˆ—è¡¨"""
    try:
        # ä½¿ç”¨PyAudioè·å–è®¾å¤‡ä¿¡æ¯
        p = pyaudio.PyAudio()
        devices = []
        
        for i in range(p.get_device_count()):
            device_info = p.get_device_info_by_index(i)
            # æŸ¥æ‰¾æ”¯æŒè¾“å…¥çš„è®¾å¤‡ï¼ˆç”¨äºç¯å›å½•éŸ³ï¼‰
            if device_info['maxInputChannels'] > 0:
                devices.append({
                    'index': i,
                    'name': device_info['name'],
                    'sample_rate': int(device_info['defaultSampleRate']),
                    'type': 'input'
                })
            # ä¹Ÿæ·»åŠ è¾“å‡ºè®¾å¤‡ä¿¡æ¯ä¾›å‚è€ƒ
            elif device_info['maxOutputChannels'] > 0:
                devices.append({
                    'index': i,
                    'name': device_info['name'] + ' (è¾“å‡ºè®¾å¤‡)',
                    'sample_rate': int(device_info['defaultSampleRate']),
                    'type': 'output'
                })
        
        p.terminate()
        return devices
    except Exception as e:
        print(f"è·å–éŸ³é¢‘è®¾å¤‡åˆ—è¡¨å¤±è´¥: {e}")
        return []

# Function to find stereo mix or similar loopback devices
def find_loopback_devices():
    """æŸ¥æ‰¾ç¯å›å½•éŸ³è®¾å¤‡ï¼ˆå¦‚ç«‹ä½“å£°æ··éŸ³ï¼‰"""
    devices = get_system_audio_devices()
    loopback_devices = []
    
    # å¸¸è§çš„ç¯å›å½•éŸ³è®¾å¤‡åç§°å…³é”®è¯
    loopback_keywords = ['stereo mix', 'what u hear', 'wave out mix', 'mixed output', 
                        'ç«‹ä½“å£°æ··éŸ³', 'æ‚¨å¬åˆ°çš„å£°éŸ³', 'æ··åˆè¾“å‡º', 'loopback']
    
    for device in devices:
        if device['type'] == 'input':
            device_name_lower = device['name'].lower()
            for keyword in loopback_keywords:
                if keyword in device_name_lower:
                    loopback_devices.append(device)
                    break
    
    return loopback_devices

# Lock for controlling access to the PyAudio stream
pyaudio_lock = threading.Lock()

# Initialize global variables for microphone and audio stream
mic = None
audio_stream = None
# Queue for text updates in wx
wx_text_queue = queue.Queue()
# Queue for fixed words from ASR
asr_fixed_words = queue.Queue()


# Handle the ASR task. This function will get audio from microphone in while loop and send it to ASR.
# The streaming output of ASR will be pushed back to the wx_text_queue and  asr_fixed_words
def restart_translator(old_translator):
    """é‡å¯translator"""
    global translator_stopped, need_restart_translator
    
    try:
        # åœæ­¢æ—§çš„translator
        if old_translator and not translator_stopped:
            print("æ­£åœ¨åœæ­¢æ—§çš„translator...")
            old_translator.stop()
        
        # é‡ç½®çŠ¶æ€
        translator_stopped = False
        need_restart_translator = False
        
        # åˆ›å»ºæ–°çš„callback
        class Callback(TranslationRecognizerCallback):
            def __init__(self):
                super().__init__()
                self.sentence_ptr = 0
                self.zh_word_ptr = 0
                self.tg_word_ptr = 0

            def on_open(self) -> None:
                print('æ–°çš„TranslationRecognizerCallbackå·²æ‰“å¼€')

            def on_close(self) -> None:
                global translator_stopped
                print('TranslationRecognizerCallbackå…³é—­')
                translator_stopped = True

            def on_event(self, request_id, transcription_result, translation_result, usage) -> None:
                new_chinese_words = ''
                new_target_language_words = ''
                is_sentence_end = False

                if transcription_result != None:
                    for i, word in enumerate(transcription_result.words):
                        if word.fixed:
                            if i >= self.zh_word_ptr:
                                new_chinese_words += word.text
                                self.zh_word_ptr += 1

                if translation_result != None:
                    target_language_translation = translation_result.get_translation('zh')
                    if target_language_translation != None:
                        for i, word in enumerate(target_language_translation.words):
                            if word.fixed:
                                if i >= self.tg_word_ptr:
                                    asr_fixed_words.put([word.text, False])
                                    new_target_language_words += word.text
                                    self.tg_word_ptr += 1
                        if target_language_translation.is_sentence_end:
                            print('target_language sentence end')
                            self.sentence_ptr += 1
                            self.tg_word_ptr = 0
                            self.zh_word_ptr = 0
                            asr_fixed_words.put(['', True])
                            is_sentence_end = True
                wx_text_queue.put([transcription_result, translation_result])

        callback = Callback()

        # åˆ›å»ºæ–°çš„translator
        asr_model = config.get('asr_model', 'gummy-realtime-v1')
        print(f"ä½¿ç”¨ASRæ¨¡å‹: {asr_model}")
        
        new_translator = TranslationRecognizerRealtime(
            model=asr_model,
            format='pcm',
            sample_rate=16000,
            transcription_enabled=True,
            translation_enabled=True,
            translation_target_languages=[target_language],
            semantic_punctuation_enabled=False,
            callback=callback,
        )

        print('é‡å¯translator...')
        new_translator.start()
        print(f'æ–°translator request_id: {new_translator.get_last_request_id()}')
        
        return new_translator
        
    except Exception as e:
        print(f"é‡å¯translatorå¤±è´¥: {e}")
        translator_stopped = True
        return None

def gummyAsrTask():
    global translator_stopped, need_restart_translator
    translator_stopped = False
    
    class Callback(TranslationRecognizerCallback):
        def __init__(self):
            super().__init__()
            # Initialize pointers for tracking words
            self.sentence_ptr = 0
            self.zh_word_ptr = 0
            self.tg_word_ptr = 0

        def on_open(self) -> None:
            # When the recognizer opens, set up the audio stream
            global mic
            global audio_stream
            global audio_source
            global current_system_device
            
            with pyaudio_lock:
                print('TranslationRecognizerCallback open.')
                
                if audio_source == 'microphone' or audio_source is None:
                    # éº¦å…‹é£å½•éŸ³ï¼ˆåŒ…æ‹¬æœªé€‰æ‹©çš„æƒ…å†µé»˜è®¤ä½¿ç”¨éº¦å…‹é£ï¼‰
                    mic = pyaudio.PyAudio()
                    audio_stream = mic.open(format=pyaudio.paInt16,
                                            channels=1,
                                            rate=16000,
                                            input=True)
                    print("å·²è¿æ¥åˆ°éº¦å…‹é£")
                    
                elif audio_source == 'system':
                    # ä½¿ç”¨FFmpegæ•è·ç³»ç»ŸéŸ³é¢‘
                    print("å°è¯•ä½¿ç”¨FFmpegæ•è·ç³»ç»ŸéŸ³é¢‘...")
                    
                    if check_ffmpeg():
                        device_name = None
                        if current_system_device is not None:
                            # å¦‚æœé€‰æ‹©äº†ç‰¹å®šè®¾å¤‡
                            devices = get_windows_audio_devices()
                            if current_system_device < len(devices):
                                device_name = devices[current_system_device]['name']
                        
                        success = start_ffmpeg_audio_capture(device_name)
                        if success:
                            print("FFmpegç³»ç»ŸéŸ³é¢‘æ•è·å¯åŠ¨æˆåŠŸ")
                            # ä¸éœ€è¦è®¾ç½®PyAudioæµï¼Œå› ä¸ºæˆ‘ä»¬ä½¿ç”¨FFmpeg
                            mic = None
                            audio_stream = None
                        else:
                            print("FFmpegå¯åŠ¨å¤±è´¥ï¼Œå›é€€åˆ°éº¦å…‹é£")
                            # å›é€€åˆ°éº¦å…‹é£
                            mic = pyaudio.PyAudio()
                            audio_stream = mic.open(format=pyaudio.paInt16,
                                                    channels=1,
                                                    rate=16000,
                                                    input=True)
                    else:
                        print("æœªæ‰¾åˆ°FFmpegï¼Œå°è¯•å¤‡ç”¨æ–¹æ¡ˆ...")
                        
                        # å°è¯•ä½¿ç”¨sounddeviceä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ
                        if SOUNDDEVICE_AVAILABLE:
                            print("å°è¯•ä½¿ç”¨sounddeviceæ•è·éŸ³é¢‘...")
                            success = start_sounddevice_capture()
                            if success:
                                print("SounddeviceéŸ³é¢‘æ•è·å¯åŠ¨æˆåŠŸ")
                                mic = None
                                audio_stream = None
                            else:
                                print("Sounddeviceå¯åŠ¨å¤±è´¥ï¼Œå°è¯•è™šæ‹ŸéŸ³é¢‘è®¾å¤‡...")
                                # å°è¯•ä½¿ç”¨è™šæ‹ŸéŸ³é¢‘è®¾å¤‡
                                virtual_devices = get_virtual_audio_devices()
                                if virtual_devices and current_system_device is not None:
                                    try:
                                        mic = pyaudio.PyAudio()
                                        device_info = mic.get_device_info_by_index(current_system_device)
                                        print(f"å°è¯•è¿æ¥åˆ°è™šæ‹ŸéŸ³é¢‘è®¾å¤‡: {device_info['name']}")
                                        
                                        audio_stream = mic.open(
                                            format=pyaudio.paInt16,
                                            channels=1,
                                            rate=16000,
                                            input=True,
                                            input_device_index=current_system_device,
                                            frames_per_buffer=3200
                                        )
                                        print(f"å·²è¿æ¥åˆ°è™šæ‹ŸéŸ³é¢‘è®¾å¤‡: {device_info['name']}")
                                    except Exception as e:
                                        print(f"è¿æ¥è™šæ‹ŸéŸ³é¢‘è®¾å¤‡å¤±è´¥: {e}")
                                        # æœ€åå›é€€åˆ°éº¦å…‹é£
                                        mic = pyaudio.PyAudio()
                                        audio_stream = mic.open(format=pyaudio.paInt16,
                                                                channels=1,
                                                                rate=16000,
                                                                input=True)
                                        print("å›é€€åˆ°éº¦å…‹é£å½•éŸ³")
                                else:
                                    # æœ€åå›é€€åˆ°éº¦å…‹é£
                                    mic = pyaudio.PyAudio()
                                    audio_stream = mic.open(format=pyaudio.paInt16,
                                                            channels=1,
                                                            rate=16000,
                                                            input=True)
                                    print("å›é€€åˆ°éº¦å…‹é£å½•éŸ³")
                        else:
                            print("Sounddeviceä¸å¯ç”¨ï¼Œå°è¯•è™šæ‹ŸéŸ³é¢‘è®¾å¤‡...")
                            # å°è¯•ä½¿ç”¨è™šæ‹ŸéŸ³é¢‘è®¾å¤‡
                            virtual_devices = get_virtual_audio_devices()
                            if virtual_devices and current_system_device is not None:
                                try:
                                    mic = pyaudio.PyAudio()
                                    device_info = mic.get_device_info_by_index(current_system_device)
                                    print(f"å°è¯•è¿æ¥åˆ°è™šæ‹ŸéŸ³é¢‘è®¾å¤‡: {device_info['name']}")
                                    
                                    audio_stream = mic.open(
                                        format=pyaudio.paInt16,
                                        channels=1,
                                        rate=16000,
                                        input=True,
                                        input_device_index=current_system_device,
                                        frames_per_buffer=3200
                                    )
                                    print(f"å·²è¿æ¥åˆ°è™šæ‹ŸéŸ³é¢‘è®¾å¤‡: {device_info['name']}")
                                except Exception as e:
                                    print(f"è¿æ¥è™šæ‹ŸéŸ³é¢‘è®¾å¤‡å¤±è´¥: {e}")
                                    # æœ€åå›é€€åˆ°éº¦å…‹é£
                                    mic = pyaudio.PyAudio()
                                    audio_stream = mic.open(format=pyaudio.paInt16,
                                                            channels=1,
                                                            rate=16000,
                                                            input=True)
                                    print("å›é€€åˆ°éº¦å…‹é£å½•éŸ³")
                            else:
                                # æœ€åå›é€€åˆ°éº¦å…‹é£
                                mic = pyaudio.PyAudio()
                                audio_stream = mic.open(format=pyaudio.paInt16,
                                                        channels=1,
                                                        rate=16000,
                                                        input=True)
                                print("å›é€€åˆ°éº¦å…‹é£å½•éŸ³")
                else:
                    # é»˜è®¤ä½¿ç”¨éº¦å…‹é£
                    mic = pyaudio.PyAudio()
                    audio_stream = mic.open(format=pyaudio.paInt16,
                                            channels=1,
                                            rate=16000,
                                            input=True)
                    print("ä½¿ç”¨é»˜è®¤éº¦å…‹é£")

        def on_close(self) -> None:
            # Clean up the audio stream and microphone
            global mic
            global audio_stream
            global translator_stopped
            print('TranslationRecognizerCallback close.')
            translator_stopped = True  # æ ‡è®°translatorå·²åœæ­¢
            
            # åœæ­¢FFmpegè¿›ç¨‹
            try:
                stop_ffmpeg_audio_capture()
            except Exception as e:
                print(f"åœæ­¢FFmpegæ—¶å‡ºé”™: {e}")
            
            # åœæ­¢sounddeviceæµ
            try:
                stop_sounddevice_capture()
            except Exception as e:
                print(f"åœæ­¢sounddeviceæ—¶å‡ºé”™: {e}")
            
            if audio_stream is None:
                print('audio_stream is None')
                return
                
            try:
                if audio_stream is not None:
                    audio_stream.stop_stream()
                    audio_stream.close()
                    audio_stream = None
                if mic is not None:
                    mic.terminate()
                    mic = None
            except Exception as e:
                print(f"æ¸…ç†éŸ³é¢‘èµ„æºæ—¶å‡ºé”™: {e}")

        def on_event(
            self,
            request_id,
            transcription_result: TranscriptionResult,
            translation_result: TranslationResult,
            usage,
        ) -> None:
            new_chinese_words = ''
            new_target_language_words = ''
            is_sentence_end = False

            # Process transcription results. Only new fixed words will be pushed back.
            if transcription_result != None:
                for i, word in enumerate(transcription_result.words):
                    if word.fixed:
                        if i >= self.zh_word_ptr:
                            # print('new fixed ch word: ', word.text)
                            new_chinese_words += word.text
                            self.zh_word_ptr += 1

            # Process translation results. Only new fixed words will be pushed back.
            if translation_result != None:
                target_language_translation = translation_result.get_translation(
                    'zh')
                if target_language_translation != None:
                    for i, word in enumerate(
                            target_language_translation.words):
                        if word.fixed:
                            if i >= self.tg_word_ptr:
                                # print('new fixed {} word: '.format(
                                #     target_language, word.text))
                                asr_fixed_words.put([word.text, False])
                                new_target_language_words += word.text
                                self.tg_word_ptr += 1
                    # Check if the current sentence has ended
                    if target_language_translation.is_sentence_end:
                        print('target_language sentence end')
                        self.sentence_ptr += 1
                        self.tg_word_ptr = 0
                        self.zh_word_ptr = 0
                        asr_fixed_words.put(['', True])
                        is_sentence_end = True
            wx_text_queue.put([transcription_result, translation_result])

    callback = Callback()

    # Set up the ASR translator
    asr_model = config.get('asr_model', 'gummy-realtime-v1')
    print(f"ä½¿ç”¨ASRæ¨¡å‹: {asr_model}")
    
    translator = TranslationRecognizerRealtime(
        model=asr_model,
        format='pcm',
        sample_rate=16000,
        transcription_enabled=True,
        translation_enabled=True,
        translation_target_languages=[target_language],
        semantic_punctuation_enabled=False,
        callback=callback,
    )

    print('translator start')
    translator.start()
    print('translator request_id: {}'.format(translator.get_last_request_id()))

    # Open a file to save microphone audio data
    saved_mic_audio_file = open('mic_audio.pcm', 'wb')

    try:
        # Continuously read audio data from the microphone or FFmpeg
        pause_cleanup_counter = 0  # æš‚åœæ—¶çš„æ¸…ç†è®¡æ•°å™¨
        
        while True:  # ä¸»å¾ªç¯ï¼Œç”¨äºå¤„ç†translatoré‡å¯
            data = None
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡å¯translator
            if need_restart_translator and not listening_paused:
                print("æ£€æµ‹åˆ°éœ€è¦é‡å¯translator...")
                translator = restart_translator(translator)
                if translator is None:
                    print("é‡å¯translatorå¤±è´¥ï¼Œé€€å‡º")
                    break
                continue
            
            # æ£€æŸ¥æ˜¯å¦æš‚åœç›‘å¬
            if listening_paused:
                # æš‚åœæ—¶å®šæœŸæ¸…ç†é˜Ÿåˆ—ä¸­çš„æ—§æ•°æ®ï¼Œé¿å…ç§¯å‹è¿‡å¤š
                pause_cleanup_counter += 1
                if pause_cleanup_counter >= 50:  # æ¯5ç§’æ¸…ç†ä¸€æ¬¡é˜Ÿåˆ— (50 * 0.1ç§’)
                    if audio_source == 'system':
                        queue_size = system_audio_queue.qsize()
                        if queue_size > 50:  # å¦‚æœé˜Ÿåˆ—ä¸­æœ‰è¶…è¿‡50ä¸ªæ•°æ®å—ï¼ˆçº¦5ç§’çš„æ•°æ®ï¼‰
                            # ä¿ç•™æœ€æ–°çš„20ä¸ªæ•°æ®å—ï¼Œä¸¢å¼ƒå…¶ä½™çš„
                            discarded_count = 0
                            while system_audio_queue.qsize() > 20:
                                try:
                                    system_audio_queue.get_nowait()
                                    discarded_count += 1
                                except queue.Empty:
                                    break
                            if discarded_count > 0:
                                print(f"æš‚åœæœŸé—´æ¸…ç†äº† {discarded_count} ä¸ªéŸ³é¢‘æ•°æ®å—ï¼Œå½“å‰é˜Ÿåˆ—å¤§å°: {system_audio_queue.qsize()}")
                    pause_cleanup_counter = 0
                
                time.sleep(0.1)  # æš‚åœæ—¶çŸ­æš‚ä¼‘æ¯
                continue
            
            # å¦‚æœtranslatorå·²åœæ­¢ä¸”ä¸åœ¨æš‚åœçŠ¶æ€ï¼Œé€€å‡ºå¾ªç¯ç­‰å¾…é‡å¯
            if translator_stopped and not listening_paused:
                print("translatorå·²åœæ­¢ï¼Œç­‰å¾…é‡å¯...")
                time.sleep(0.1)
                continue
            
            if audio_source == 'system' and (ffmpeg_process is not None or sounddevice_stream is not None):
                # ä»FFmpegé˜Ÿåˆ—æˆ–sounddeviceé˜Ÿåˆ—è¯»å–éŸ³é¢‘æ•°æ®
                try:
                    data = system_audio_queue.get(timeout=0.1)
                except queue.Empty:
                    continue
            elif audio_stream:
                # ä»PyAudioæµè¯»å–éŸ³é¢‘æ•°æ®
                try:
                    data = audio_stream.read(3200, exception_on_overflow=False)
                except Exception as e:
                    print(f"PyAudioè¯»å–é”™è¯¯: {e}")
                    break
            else:
                break
            
            if data and not listening_paused and not translator_stopped:  # æ£€æŸ¥translatorçŠ¶æ€
                try:
                    translator.send_audio_frame(data)
                    saved_mic_audio_file.write(data)
                except Exception as e:
                    print(f"å‘é€éŸ³é¢‘æ•°æ®é”™è¯¯: {e}")
                    if "has stopped" in str(e):
                        print("æ£€æµ‹åˆ°translatorå·²åœæ­¢")
                        translator_stopped = True
                    # ä¸è¦breakï¼Œè®©å¾ªç¯ç»§ç»­ç­‰å¾…é‡å¯
    except Exception as e:
        print(f"éŸ³é¢‘å¤„ç†å¾ªç¯å‡ºé”™: {e}")
    finally:
        saved_mic_audio_file.close()
        
        # å®‰å…¨åœ°åœæ­¢translator
        if not translator_stopped:
            try:
                print('translator stop')
                translator.stop()
                translator_stopped = True
            except Exception as e:
                print(f"åœæ­¢translatoræ—¶å‡ºé”™: {e}")
        else:
            print('translatorå·²ç»åœæ­¢ï¼Œè·³è¿‡stopè°ƒç”¨')


# Handle the TTS task. This function will get text in asr_fixed_words in while loop and send it to TTS.
# The streaming output of TTS will be played back by the player.
def cosyvoiceTtsTask():
    global config
    
    # Replace with SiliconFlow CosyVoice API
    url = "https://api.siliconflow.cn/v1/audio/speech"
    
    # è·å–API key
    api_key = config.get('siliconflow_api_key', '<your-SiliconFlow-api-key>')
    if 'SILICONFLOW_API_KEY' in os.environ:
        api_key = os.environ['SILICONFLOW_API_KEY']
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    voice = config.get('tts_voice', 'FunAudioLLM/CosyVoice2-0.5B:alex')
    buffer = ''

    # Continuously check for new words to synthesize
    while True:
        if not enable_tts:
            time.sleep(0.1)
            continue
        if not asr_fixed_words.empty():
            if not enable_tts:
                time.sleep(0.1)
                continue  # å¦‚æœ TTS ç¦ç”¨ï¼Œåˆ™è·³è¿‡æœ¬æ¬¡å¾ªç¯
            word, is_sentence_end = asr_fixed_words.get()
            if is_sentence_end  or ((word == 'ã€' or word == 'ï¼Œ' or word == 'ã€‚' ) and len(buffer) > 15) :
            #if is_sentence_end  or (word == 'ã€' or word == 'ï¼Œ' or word == 'ã€‚' ) :

                # when the sentence ends, wait for the previous sentence to finish synthesing and playing.
                #player.stop()
                #player.reset()
                #player.start()
                word += '[breath][breath][breath]'
                buffer += word
                # buffer += '[breath][breath][breath]'
                print('send sentence: ', buffer)
                payload = {
                    "model": "FunAudioLLM/CosyVoice2-0.5B",
                    "input": buffer,
                    "voice": voice,
                    "response_format": "pcm",
                    "sample_rate": 24000,
                    "stream": True,
                    "speed": 1.4,
                    "gain": 0
                }

                
                buffer_size = 4096  # ç¼“å†²åŒºå¤§å°
                try:
                    response = requests.request("POST", url, json=payload, headers=headers, stream=True)
                    if response.status_code == 200:
                        p = pyaudio.PyAudio()
                        stream = p.open(format=8, channels=1, rate=24000, output=True) #ä¿®æ”¹formatå‚æ•°
                        buffer2 = b""  # åˆå§‹åŒ–ç¼“å†²åŒº
                        for chunk in response.iter_content(chunk_size=1024):
                            if chunk:
                                #print("len_chunk:", len(chunk))
                                buffer2 += chunk  # å°†æ•°æ®å—æ·»åŠ åˆ°ç¼“å†²åŒº
                                #print("len_buffer:",len(buffer2))
                                while len(buffer2) >= buffer_size:  # å½“ç¼“å†²åŒºè¾¾åˆ°ä¸€å®šå¤§å°æ—¶
                                    data_to_play = buffer2[:buffer_size]  # ä»ç¼“å†²åŒºä¸­å–å‡ºæ•°æ®
                                    stream.write(data_to_play)  # æ’­æ”¾æ•°æ®
                                    buffer2 = buffer2[buffer_size:]  # æ›´æ–°ç¼“å†²åŒº
                        # æ’­æ”¾å‰©ä½™çš„ç¼“å†²åŒºæ•°æ®
                        if len(buffer2) > 0 :
                            stream.write(buffer2)
                        stream.stop_stream()
                        stream.close()
                        p.terminate() 
                    else:
                        print(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}")
                    buffer = ''
                except requests.exceptions.RequestException as e:
                    print(f"è¯·æ±‚å¼‚å¸¸: {e}")
                except Exception as e :
                    print(f"å…¶ä»–å¼‚å¸¸ï¼š{e}")
            else:
                buffer += word
                #print('buffer: ', buffer)
                    
        else:
            # Sleep briefly if no words are available
            time.sleep(0.01)

class SettingsDialog(wx.Dialog):
    """è®¾ç½®å¯¹è¯æ¡†"""
    
    def __init__(self, parent, config):
        super().__init__(parent, title="è®¾ç½®", size=(500, 400))
        
        self.config = config.copy()
        
        # åˆ›å»ºä¸»é¢æ¿
        panel = wx.Panel(self)
        main_sizer = wx.BoxSizer(wx.VERTICAL)
        
        # åˆ›å»ºç¬”è®°æœ¬æ§ä»¶ï¼ˆæ ‡ç­¾é¡µï¼‰
        notebook = wx.Notebook(panel)
        
        # APIè®¾ç½®é¡µé¢
        api_panel = wx.Panel(notebook)
        api_sizer = wx.BoxSizer(wx.VERTICAL)
        
        # DashScope API Key
        api_sizer.Add(wx.StaticText(api_panel, label="DashScope API Key:"), 0, wx.ALL, 5)
        self.dashscope_key = wx.TextCtrl(api_panel, value=self.config.get('dashscope_api_key', ''))
        api_sizer.Add(self.dashscope_key, 0, wx.EXPAND | wx.ALL, 5)
        
        # SiliconFlow API Key
        api_sizer.Add(wx.StaticText(api_panel, label="SiliconFlow API Key:"), 0, wx.ALL, 5)
        self.siliconflow_key = wx.TextCtrl(api_panel, value=self.config.get('siliconflow_api_key', ''))
        api_sizer.Add(self.siliconflow_key, 0, wx.EXPAND | wx.ALL, 5)
        
        # TTS Voice
        api_sizer.Add(wx.StaticText(api_panel, label="TTS Voice:"), 0, wx.ALL, 5)
        voice_choices = [
            'FunAudioLLM/CosyVoice2-0.5B:alex',
            'FunAudioLLM/CosyVoice2-0.5B:bella',
            'FunAudioLLM/CosyVoice2-0.5B:carter',
            'FunAudioLLM/CosyVoice2-0.5B:emma'
        ]
        self.tts_voice = wx.Choice(api_panel, choices=voice_choices)
        current_voice = self.config.get('tts_voice', voice_choices[0])
        if current_voice in voice_choices:
            self.tts_voice.SetSelection(voice_choices.index(current_voice))
        else:
            self.tts_voice.SetSelection(0)
        api_sizer.Add(self.tts_voice, 0, wx.EXPAND | wx.ALL, 5)
        
        # ASR Model
        api_sizer.Add(wx.StaticText(api_panel, label="ASRæ¨¡å‹:"), 0, wx.ALL, 5)
        model_choices = [
            'gummy-realtime-v1',
            'paraformer-realtime-v1',
            'paraformer-realtime-v2',
            'sensevoice-realtime-v1'
        ]
        self.asr_model = wx.Choice(api_panel, choices=model_choices)
        current_model = self.config.get('asr_model', model_choices[0])
        if current_model in model_choices:
            self.asr_model.SetSelection(model_choices.index(current_model))
            custom_model_value = ""
        else:
            self.asr_model.SetSelection(0)
            custom_model_value = current_model
        api_sizer.Add(self.asr_model, 0, wx.EXPAND | wx.ALL, 5)
        
        # æˆ–è€…ä½¿ç”¨æ–‡æœ¬æ¡†è®©ç”¨æˆ·è‡ªå®šä¹‰è¾“å…¥æ¨¡å‹åç§°
        api_sizer.Add(wx.StaticText(api_panel, label="è‡ªå®šä¹‰ASRæ¨¡å‹ (å¯é€‰):"), 0, wx.ALL, 5)
        self.custom_asr_model = wx.TextCtrl(api_panel, value=custom_model_value)
        api_sizer.Add(self.custom_asr_model, 0, wx.EXPAND | wx.ALL, 5)
        
        # æ·»åŠ è¯´æ˜æ–‡å­—
        help_text = wx.StaticText(api_panel, label="æç¤º: å¦‚æœå¡«å†™äº†è‡ªå®šä¹‰æ¨¡å‹åç§°ï¼Œå°†ä¼˜å…ˆä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹")
        help_text.SetForegroundColour(wx.Colour(100, 100, 100))
        api_sizer.Add(help_text, 0, wx.ALL, 5)
        
        api_panel.SetSizer(api_sizer)
        notebook.AddPage(api_panel, "APIè®¾ç½®")
        
        # è·¯å¾„è®¾ç½®é¡µé¢
        path_panel = wx.Panel(notebook)
        path_sizer = wx.BoxSizer(wx.VERTICAL)
        
        # FFmpegè·¯å¾„
        path_sizer.Add(wx.StaticText(path_panel, label="FFmpegå¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„:"), 0, wx.ALL, 5)
        ffmpeg_sizer = wx.BoxSizer(wx.HORIZONTAL)
        self.ffmpeg_path = wx.TextCtrl(path_panel, value=self.config.get('ffmpeg_path', '') or '')
        ffmpeg_sizer.Add(self.ffmpeg_path, 1, wx.ALL, 5)
        
        browse_btn = wx.Button(path_panel, label="æµè§ˆ...")
        browse_btn.Bind(wx.EVT_BUTTON, self.on_browse_ffmpeg)
        ffmpeg_sizer.Add(browse_btn, 0, wx.ALL, 5)
        
        path_sizer.Add(ffmpeg_sizer, 0, wx.EXPAND)
        
        # è‡ªåŠ¨æ£€æµ‹æŒ‰é’®
        detect_btn = wx.Button(path_panel, label="è‡ªåŠ¨æ£€æµ‹FFmpeg")
        detect_btn.Bind(wx.EVT_BUTTON, self.on_detect_ffmpeg)
        path_sizer.Add(detect_btn, 0, wx.ALL, 5)
        
        path_panel.SetSizer(path_sizer)
        notebook.AddPage(path_panel, "è·¯å¾„è®¾ç½®")
        
        # éŸ³é¢‘è®¾ç½®é¡µé¢
        audio_panel = wx.Panel(notebook)
        audio_sizer = wx.BoxSizer(wx.VERTICAL)
        
        # éŸ³é¢‘æºé€‰æ‹©
        audio_sizer.Add(wx.StaticText(audio_panel, label="é»˜è®¤éŸ³é¢‘æº:"), 0, wx.ALL, 5)
        self.audio_source = wx.Choice(audio_panel, choices=["éº¦å…‹é£", "ç³»ç»ŸéŸ³é¢‘"])
        self.audio_source.SetSelection(0 if self.config.get('audio_source') == 'microphone' else 1)
        audio_sizer.Add(self.audio_source, 0, wx.EXPAND | wx.ALL, 5)
        
        # ç›®æ ‡è¯­è¨€
        audio_sizer.Add(wx.StaticText(audio_panel, label="ç¿»è¯‘ç›®æ ‡è¯­è¨€:"), 0, wx.ALL, 5)
        lang_choices = ["zh", "en", "ja", "ko", "fr", "es", "de", "ru"]
        self.target_language = wx.Choice(audio_panel, choices=lang_choices)
        target_lang = self.config.get('target_language', 'zh')
        if target_lang in lang_choices:
            self.target_language.SetSelection(lang_choices.index(target_lang))
        else:
            self.target_language.SetSelection(0)
        audio_sizer.Add(self.target_language, 0, wx.EXPAND | wx.ALL, 5)
        
        # TTSå¯ç”¨
        self.enable_tts = wx.CheckBox(audio_panel, label="é»˜è®¤å¯ç”¨TTS")
        self.enable_tts.SetValue(self.config.get('enable_tts', False))
        audio_sizer.Add(self.enable_tts, 0, wx.ALL, 5)
        
        audio_panel.SetSizer(audio_sizer)
        notebook.AddPage(audio_panel, "éŸ³é¢‘è®¾ç½®")
        
        main_sizer.Add(notebook, 1, wx.EXPAND | wx.ALL, 10)
        
        # æŒ‰é’®
        btn_sizer = wx.BoxSizer(wx.HORIZONTAL)
        
        test_btn = wx.Button(panel, label="æµ‹è¯•è®¾ç½®")
        test_btn.Bind(wx.EVT_BUTTON, self.on_test_settings)
        btn_sizer.Add(test_btn, 0, wx.ALL, 5)
        
        btn_sizer.AddStretchSpacer()
        
        cancel_btn = wx.Button(panel, wx.ID_CANCEL, "å–æ¶ˆ")
        btn_sizer.Add(cancel_btn, 0, wx.ALL, 5)
        
        ok_btn = wx.Button(panel, wx.ID_OK, "ç¡®å®š")
        btn_sizer.Add(ok_btn, 0, wx.ALL, 5)
        
        main_sizer.Add(btn_sizer, 0, wx.EXPAND | wx.ALL, 10)
        
        panel.SetSizer(main_sizer)
        
        self.Center()
    
    def on_browse_ffmpeg(self, event):
        """æµè§ˆFFmpegæ–‡ä»¶"""
        wildcard = "å¯æ‰§è¡Œæ–‡ä»¶ (*.exe)|*.exe|æ‰€æœ‰æ–‡ä»¶ (*.*)|*.*"
        dialog = wx.FileDialog(self, "é€‰æ‹©FFmpegå¯æ‰§è¡Œæ–‡ä»¶", 
                              wildcard=wildcard, style=wx.FD_OPEN)
        
        if dialog.ShowModal() == wx.ID_OK:
            self.ffmpeg_path.SetValue(dialog.GetPath())
        
        dialog.Destroy()
    
    def on_detect_ffmpeg(self, event):
        """è‡ªåŠ¨æ£€æµ‹FFmpeg"""
        # ä¸´æ—¶ä¿å­˜å½“å‰é…ç½®
        old_ffmpeg_path = self.config.get('ffmpeg_path')
        
        # æ¸…é™¤é…ç½®ä¸­çš„FFmpegè·¯å¾„ä»¥è§¦å‘è‡ªåŠ¨æ£€æµ‹
        self.config['ffmpeg_path'] = None
        
        if check_ffmpeg():
            global ffmpeg_path
            self.ffmpeg_path.SetValue(ffmpeg_path or '')
            wx.MessageBox(f"æ£€æµ‹åˆ°FFmpeg: {ffmpeg_path}", "æ£€æµ‹æˆåŠŸ", wx.OK | wx.ICON_INFORMATION)
        else:
            wx.MessageBox("æœªæ£€æµ‹åˆ°FFmpegï¼Œè¯·æ‰‹åŠ¨æŒ‡å®šè·¯å¾„", "æ£€æµ‹å¤±è´¥", wx.OK | wx.ICON_WARNING)
        
        # æ¢å¤åŸé…ç½®
        self.config['ffmpeg_path'] = old_ffmpeg_path
    
    def on_test_settings(self, event):
        """æµ‹è¯•è®¾ç½®"""
        # è·å–å½“å‰è®¾ç½®
        test_config = self.get_config()
        
        # æµ‹è¯•FFmpeg
        if test_config.get('ffmpeg_path'):
            if os.path.exists(test_config['ffmpeg_path']):
                try:
                    result = subprocess.run([test_config['ffmpeg_path'], '-version'], 
                                          capture_output=True, text=True, timeout=5)
                    if result.returncode == 0:
                        ffmpeg_status = "âœ… FFmpegæµ‹è¯•æˆåŠŸ"
                    else:
                        ffmpeg_status = "âŒ FFmpegæ— æ³•è¿è¡Œ"
                except Exception as e:
                    ffmpeg_status = f"âŒ FFmpegæµ‹è¯•å¤±è´¥: {e}"
            else:
                ffmpeg_status = "âŒ FFmpegè·¯å¾„ä¸å­˜åœ¨"
        else:
            ffmpeg_status = "âš ï¸ æœªè®¾ç½®FFmpegè·¯å¾„"
        
        # æµ‹è¯•API Keyï¼ˆç®€å•éªŒè¯æ ¼å¼ï¼‰
        dashscope_key = test_config.get('dashscope_api_key', '')
        if dashscope_key and dashscope_key != '<your-dashscope-api-key>':
            dashscope_status = "âœ… DashScope API Keyå·²è®¾ç½®"
        else:
            dashscope_status = "âŒ DashScope API Keyæœªè®¾ç½®"
        
        siliconflow_key = test_config.get('siliconflow_api_key', '')
        if siliconflow_key and siliconflow_key != '<your-SiliconFlow-api-key>':
            siliconflow_status = "âœ… SiliconFlow API Keyå·²è®¾ç½®"
        else:
            siliconflow_status = "âŒ SiliconFlow API Keyæœªè®¾ç½®"
        
        # æ˜¾ç¤ºæµ‹è¯•ç»“æœ
        message = f"è®¾ç½®æµ‹è¯•ç»“æœ:\n\n{ffmpeg_status}\n{dashscope_status}\n{siliconflow_status}"
        wx.MessageBox(message, "è®¾ç½®æµ‹è¯•", wx.OK | wx.ICON_INFORMATION)
    
    def get_config(self):
        """è·å–ç”¨æˆ·è®¾ç½®çš„é…ç½®"""
        config = {}
        
        # APIè®¾ç½®
        config['dashscope_api_key'] = self.dashscope_key.GetValue().strip()
        config['siliconflow_api_key'] = self.siliconflow_key.GetValue().strip()
        config['tts_voice'] = self.tts_voice.GetStringSelection()
        
        # ASRæ¨¡å‹è®¾ç½®
        custom_model = self.custom_asr_model.GetValue().strip()
        if custom_model:
            config['asr_model'] = custom_model
        else:
            config['asr_model'] = self.asr_model.GetStringSelection()
        
        # è·¯å¾„è®¾ç½®
        ffmpeg_path = self.ffmpeg_path.GetValue().strip()
        config['ffmpeg_path'] = ffmpeg_path if ffmpeg_path else None
        
        # éŸ³é¢‘è®¾ç½®
        config['audio_source'] = 'microphone' if self.audio_source.GetSelection() == 0 else 'system'
        config['target_language'] = self.target_language.GetStringSelection()
        config['enable_tts'] = self.enable_tts.GetValue()
        
        return config

class FloatingSubtitleWindow(wx.Frame):
    def __init__(self):
        # åˆå§‹åŒ–èƒŒæ™¯ç›¸å…³å±æ€§
        self.is_dark_mode = False  # åˆå§‹ä¸ºäº®è‰²æ¨¡å¼
        self.bg_alpha = 0  # åˆå§‹èƒŒæ™¯é€æ˜åº¦å€¼(0-255)
        self.text_color = wx.Colour(0, 0, 0)  # åˆå§‹æ–‡å­—é¢œè‰²
        # æ ¹æ®åˆå§‹æ¨¡å¼è®¾ç½®èƒŒæ™¯é¢œè‰²
        brightness = int((255 - self.bg_alpha) * 1)
        self.bg_color = wx.Colour(brightness, brightness, brightness) if not self.is_dark_mode else wx.Colour(0, 0, 0)
        
        # è®¾ç½®èƒŒæ™¯æ ·å¼ä¸ºé€æ˜
        style = wx.STAY_ON_TOP | wx.RESIZE_BORDER | wx.DEFAULT_FRAME_STYLE
        
        super().__init__(
            parent=None,
            title='å®æ—¶ç¿»è¯‘å­—å¹•',
            style=style
        )
        
        # å±æ€§åˆå§‹åŒ–
        self.transparency = 255
        self.font_size = 14
        self.font_family = wx.FONTFAMILY_DEFAULT
        self.text_color = wx.Colour(0, 0, 0)
        self.MAX_CHARS = 1000

        self.SetSize((900,110))
    
        # æ·»åŠ æ–‡æœ¬é¢æ¿é€æ˜åº¦å±æ€§
        self.text_alpha = 128  # åˆå§‹èƒŒæ™¯é€æ˜åº¦å€¼
        self.background_color = wx.Colour(0, 0, 0)  # é»‘è‰²èƒŒæ™¯
        
        # åˆå§‹åŒ–æ–‡æœ¬é¢æ¿èƒŒæ™¯é€æ˜åº¦
        self.panel_alpha = 200  # åˆå§‹é€æ˜åº¦å€¼ï¼Œå¢å¤§åˆå§‹å€¼ä½¿æ–‡æœ¬æ›´å®¹æ˜“çœ‹è§
        
        if wx.Platform == "__WXMSW__":
            # å¯ç”¨çª—å£é€æ˜
            hwnd = self.GetHandle()
            GWL_EXSTYLE = -20
            WS_EX_LAYERED = 0x80000
            style = ctypes.windll.user32.GetWindowLongW(hwnd, GWL_EXSTYLE)
            ctypes.windll.user32.SetWindowLongW(hwnd, GWL_EXSTYLE, style | WS_EX_LAYERED)
            
            # è®¾ç½®æ•´ä¸ªçª—å£çš„åˆå§‹é€æ˜åº¦
            ctypes.windll.user32.SetLayeredWindowAttributes(hwnd, 0, self.panel_alpha, 0x02)
        
        # åˆ›å»ºä¸»é¢æ¿
        self.panel = wx.Panel(self, style=wx.BORDER_NONE)
        self.panel.SetBackgroundColour(wx.Colour(255, 255, 255, 0))
        
        # åˆå§‹åŒ–å¸ƒå±€
        self.main_sizer = wx.BoxSizer(wx.VERTICAL)
        
        # åˆ›å»ºæ–‡æœ¬é¢æ¿
        self.chinese_panel = self.create_language_panel("æºè¯­è¨€", "chinese_text_box")
        self.target_panel = self.create_language_panel("ç›®æ ‡è¯­è¨€", "target_language_text_box")
        
        # æ·»åŠ åˆ°å¸ƒå±€
        self.main_sizer.Add(self.chinese_panel, 0, wx.EXPAND | wx.ALL, 2)
        self.main_sizer.AddSpacer(5)  # æ·»åŠ ä¸€ä¸ªé«˜åº¦ä¸º 10 çš„ç©ºç™½åŒºåŸŸ
        self.main_sizer.Add(self.target_panel, 1, wx.EXPAND | wx.ALL, 2)
        
        # åˆ›å»ºçŠ¶æ€æ 
        self.status_bar = self.CreateStatusBar(1)
        self.update_status_bar()
        
        self.panel.SetSizer(self.main_sizer)
        
        # åˆå§‹åŒ–ç¼“å†²åŒº
        self.chinese_buffer = ''
        self.chinese_text_buffer = [['', '']]  # æºè¯­è¨€æ–‡æœ¬ç¼“å†²åŒº
        self.target_language_text_buffer = [['', '']]  # ç›®æ ‡è¯­è¨€æ–‡æœ¬ç¼“å†²åŒº

        # è®¾ç½®å®šæ—¶å™¨ç”¨äºæ›´æ–°æ–‡æœ¬
        self.timer = wx.Timer(self)
        self.Bind(wx.EVT_TIMER, self.on_timer, self.timer)
        self.timer.Start(100)  # æ¯100æ¯«ç§’æ›´æ–°ä¸€æ¬¡

        # ç»‘å®šå¿«æ·é”®äº‹ä»¶
        self.Bind(wx.EVT_CHAR_HOOK, self.on_key_press)

        # æ·»åŠ æ‹–æ‹½ç›¸å…³å±æ€§
        self.dragging = False
        self.drag_start_pos = None

        self.has_titlebar = True  # åˆå§‹çŠ¶æ€ä¸ºæ˜¾ç¤ºæ ‡é¢˜æ 

        # è®¾ç½®æœ€å°çª—å£å¤§å°
        self.SetMinSize((300, 100))

        # åˆ›å»ºå®šæ—¶å™¨ï¼Œæ¯100æ¯«ç§’æ£€æŸ¥ä¸€æ¬¡é¼ æ ‡ä½ç½®
        self.mouse_check_timer = wx.Timer(self)
        self.Bind(wx.EVT_TIMER, self.check_mouse_position, self.mouse_check_timer)
        self.mouse_check_timer.Start(100)  # 100æ¯«ç§’é—´éš”

        self.Center()
        self.Show()


    def check_mouse_position(self, event):
        """å®šæ—¶æ£€æŸ¥é¼ æ ‡ä½ç½®"""
        x, y = wx.GetMousePosition()  # è·å–é¼ æ ‡å…¨å±€åæ ‡
        rect = self.GetScreenRect()  # è·å–çª—å£å…¨å±€åæ ‡çš„çŸ©å½¢åŒºåŸŸ
        if not rect.Contains(wx.Point(x, y)):
            if self.has_titlebar:
                #print("Mouse left the window (timer)")
                self.SetWindowStyleFlag(self.GetWindowStyleFlag() & ~wx.CAPTION)
                self.has_titlebar = False
                self.Refresh()
        else:
            if not self.has_titlebar:
                #print("Mouse in the window (timer)")
                self.SetWindowStyleFlag(self.GetWindowStyleFlag() | wx.CAPTION)
                self.has_titlebar = True
                self.Refresh()
    
    on_mouse_enter = None  # ç§»é™¤é¼ æ ‡è¿›å…¥äº‹ä»¶å¤„ç†
    show_titlebar = None  # ç§»é™¤æ˜¾ç¤ºæ ‡é¢˜æ å‡½æ•°
    on_mouse_leave = None  # ç§»é™¤é¼ æ ‡ç¦»å¼€äº‹ä»¶å¤„ç†
    hide_titlebar = None  # ç§»é™¤éšè—æ ‡é¢˜æ å‡½æ•°

    def on_timer(self, event):
        """å¤„ç†å®šæ—¶å™¨äº‹ä»¶ï¼Œä»é˜Ÿåˆ—ä¸­è·å–å¹¶æ›´æ–°æ–‡æœ¬"""
        try:
            while not wx_text_queue.empty():
                transcription_result, translation_result = wx_text_queue.get()
                self.update_text(transcription_result, translation_result)
        except Exception as e:
            print(f"å®šæ—¶å™¨æ›´æ–°å‡ºé”™: {e}")
        event.Skip()

    def create_language_panel(self, title, text_box_name):
        panel = wx.Panel(self.panel)

        text_box = rt.RichTextCtrl(
            panel,
            style=wx.NO_BORDER | rt.RE_READONLY | rt.RE_MULTILINE
        )
        # text_box = stc.StyledTextCtrl(
        #     panel,
        #     style=wx.NO_BORDER
        # )
        text_box.SetMinSize((300, 25))

        font = wx.Font(
            wx.FontInfo(self.font_size)  # å­—å·
                .Family(wx.FONTFAMILY_DEFAULT)
                .Style(wx.FONTSTYLE_NORMAL)
                .Weight(wx.FONTWEIGHT_NORMAL)
                .AntiAliased(True)  # å…³é”®ï¼šå¯ç”¨æŠ—é”¯é½¿
                #.FaceName("å¾®è½¯é›…é»‘")
        )
        text_box.SetFont(font)

        # è®¾ç½®åˆå§‹èƒŒæ™¯è‰²
        text_box.SetBackgroundColour(self.bg_color)
        text_box.SetMargins(5, 2)

        # è®¾ç½®æ–‡å­—é¢œè‰²å’Œæ ·å¼
        #attr = wx.TextAttr()

        attr = rt.RichTextAttr()
        attr.SetAlignment(wx.TEXT_ALIGNMENT_LEFT)  #å·¦å¯¹é½
        attr.SetLineSpacing(14)  # è®¾ç½®è¡Œé—´è·

        attr.SetTextColour(self.text_color)
        text_box.SetDefaultStyle(attr)

        sizer = wx.BoxSizer(wx.VERTICAL)
        #label = wx.StaticText(panel, label=title)
        #sizer.Add(label, 0, wx.EXPAND | wx.ALL, 1)
        sizer.Add(text_box, 1, wx.EXPAND | wx.ALL, 1)
        panel.SetSizer(sizer)

        setattr(self, text_box_name, text_box)

        return panel

    def set_panel_alpha(self, alpha):
        """è®¾ç½®æ–‡æœ¬é¢æ¿èƒŒæ™¯é€æ˜åº¦"""
        try:
            self.bg_alpha = alpha
            # æ ¹æ®é¢œè‰²æ¨¡å¼è®¡ç®—èƒŒæ™¯äº®åº¦å’Œé¢œè‰²
            # ç»Ÿä¸€äº®åº¦è®¡ç®—é€»è¾‘ï¼Œä¸¤ç§æ¨¡å¼éƒ½åŸºäºalphaå€¼
            brightness = int(1*(255 - alpha))  # åŸºç¡€äº®åº¦å€¼
            self.bg_color = wx.Colour(brightness, brightness, brightness)

            self.chinese_text_box.Freeze()
            self.target_language_text_box.Freeze()

            # æ›´æ–°èƒŒæ™¯è‰²
            self.chinese_text_box.SetBackgroundColour(self.bg_color)
            self.target_language_text_box.SetBackgroundColour(self.bg_color)
            self.panel.SetBackgroundColour(self.bg_color)
            self.SetBackgroundColour(self.bg_color)

            # ç¡®ä¿æ–‡å­—é¢œè‰²ä¸å˜
            # attr = wx.TextAttr()
            # attr.SetTextColour(self.text_color)
            # self.chinese_text_box.SetDefaultStyle(attr)
            # self.target_language_text_box.SetDefaultStyle(attr)

            # åˆ·æ–°æ˜¾ç¤º
            self.chinese_text_box.Refresh()
            self.target_language_text_box.Refresh()
            self.Refresh()

            self.chinese_text_box.Thaw()
            self.target_language_text_box.Thaw()

            print(f"èƒŒæ™¯é€æ˜åº¦å·²æ›´æ–°: alpha={alpha}, äº®åº¦å€¼={brightness}")
        except Exception as e:
            print(f"è®¾ç½®èƒŒæ™¯é€æ˜åº¦æ—¶å‡ºé”™: {e}")
            if self.chinese_text_box.IsFrozen():
                self.chinese_text_box.Thaw()
            if self.target_language_text_box.IsFrozen():
                self.target_language_text_box.Thaw()

    def update_status_bar(self):
        """æ›´æ–°çŠ¶æ€æ ä¿¡æ¯"""
        global audio_source, enable_tts, listening_paused, config, ffmpeg_path
        
        # éŸ³é¢‘æºçŠ¶æ€
        audio_status = "ğŸ¤ éº¦å…‹é£" if audio_source == 'microphone' else "ğŸ”Š ç³»ç»ŸéŸ³é¢‘"
        
        # TTSçŠ¶æ€
        tts_status = "ğŸ”Š TTSå¼€" if enable_tts else "ğŸ”‡ TTSå…³"
        
        # ç›‘å¬çŠ¶æ€
        listening_status = "â¸ï¸ å·²æš‚åœ" if listening_paused else "ğŸ§ ç›‘å¬ä¸­"
        
        # FFmpegçŠ¶æ€
        ffmpeg_status = "FFmpegâœ…" if check_ffmpeg() else "FFmpegâŒ"
        
        status_text = f"{audio_status} | {tts_status} | {listening_status} | {ffmpeg_status}"
        self.status_bar.SetStatusText(status_text, 0)

    def show_settings_dialog(self):
        """æ˜¾ç¤ºè®¾ç½®å¯¹è¯æ¡†"""
        global config, ffmpeg_path, audio_source, target_language, current_system_device, enable_tts, enable_api_calls
        
        dialog = SettingsDialog(self, config)
        if dialog.ShowModal() == wx.ID_OK:
            # è·å–æ›´æ–°åçš„é…ç½®
            new_config = dialog.get_config()
            config.update(new_config)
            
            # åŒæ­¥æ›´æ–°å…¨å±€å˜é‡
            ffmpeg_path = config.get('ffmpeg_path', None)
            audio_source = config.get('audio_source', 'system')
            target_language = config.get('target_language', 'zh')
            current_system_device = config.get('current_system_device', None)
            enable_tts = config.get('enable_tts', False)
            enable_api_calls = config.get('api', {}).get('enabled', True)
            
            # ä¿å­˜é…ç½®
            save_config()
            
            # æ›´æ–°çŠ¶æ€æ 
            self.update_status_bar()
            
            wx.MessageBox(
                "è®¾ç½®å·²ä¿å­˜ï¼\néƒ¨åˆ†è®¾ç½®éœ€è¦é‡å¯ç¨‹åºæ‰èƒ½ç”Ÿæ•ˆã€‚",
                "è®¾ç½®ä¿å­˜æˆåŠŸ",
                wx.OK | wx.ICON_INFORMATION
            )
        
        dialog.Destroy()

    def toggle_listening(self):
        """åˆ‡æ¢ç›‘å¬æš‚åœ/æ¢å¤çŠ¶æ€"""
        global listening_paused, translator_stopped, need_restart_translator
        
        if listening_paused:
            # ä»æš‚åœçŠ¶æ€æ¢å¤
            if translator_stopped:
                # å¦‚æœtranslatorå·²åœæ­¢ï¼Œæ ‡è®°éœ€è¦é‡å¯
                need_restart_translator = True
                print("éŸ³é¢‘ç›‘å¬å·²æ¢å¤ - translatorå°†é‡å¯")
            else:
                print("éŸ³é¢‘ç›‘å¬å·²æ¢å¤")
            listening_paused = False
        else:
            # æš‚åœç›‘å¬
            listening_paused = True
            print("éŸ³é¢‘ç›‘å¬å·²æš‚åœ")
        
        # æ›´æ–°çŠ¶æ€æ 
        self.update_status_bar()

    def on_key_press(self, event):
        key = event.GetKeyCode()
        if event.AltDown():
            if key == ord('T') or key == ord('t'):  # æ£€æµ‹Alt+T
                self.toggle_color_mode()
                return
            if key == ord('A') or key == ord('a'):  # æ£€æµ‹Alt+A - åˆ‡æ¢éŸ³é¢‘æº
                self.toggle_audio_source()
                return
            if key == ord('D') or key == ord('d'):  # æ£€æµ‹Alt+D - é€‰æ‹©ç³»ç»ŸéŸ³é¢‘è®¾å¤‡
                self.show_audio_device_dialog()
                return
            if key == ord('P') or key == ord('p'):  # æ£€æµ‹Alt+P - æš‚åœ/æ¢å¤ç›‘å¬
                self.toggle_listening()
                return
            if key == ord('S') or key == ord('s'):  # æ£€æµ‹ Alt+S - æ‰“å¼€è®¾ç½®
                self.show_settings_dialog()
                return
            if key == wx.WXK_UP or key == wx.WXK_DOWN:
                new_alpha = self.bg_alpha
                if key == wx.WXK_UP:
                    new_alpha = min(255, self.bg_alpha + 20)
                else:
                    new_alpha = max(0, self.bg_alpha - 20)

                self.set_panel_alpha(new_alpha)
                return
        if event.ControlDown():
            if key == ord('H') or key == ord('h'):  # æ£€æµ‹Ctrl+H
                self.on_toggle_titlebar()
                return
        event.Skip()

    def on_toggle_titlebar(self):
        """åˆ‡æ¢æ ‡é¢˜æ çš„æ˜¾ç¤ºå’Œéšè—"""
        if self.has_titlebar:
            self.SetWindowStyle(self.GetWindowStyle() & ~wx.CAPTION)
            self.has_titlebar = False
        else:
            self.SetWindowStyle(self.GetWindowStyle() | wx.CAPTION)
            self.has_titlebar = True
        self.Refresh()

    def toggle_audio_source(self):
        """åˆ‡æ¢éŸ³é¢‘æºï¼šéº¦å…‹é£ <-> ç³»ç»ŸéŸ³é¢‘"""
        global audio_source
        
        if audio_source == 'microphone' or audio_source is None:
            audio_source = 'system'
            source_name = "ç³»ç»ŸéŸ³é¢‘"
        else:
            audio_source = 'microphone'
            source_name = "éº¦å…‹é£å½•éŸ³"
        
        print(f"å·²åˆ‡æ¢åˆ°: {source_name}")
        
        # æ›´æ–°çŠ¶æ€æ 
        self.update_status_bar()
        
        # ä¿å­˜é…ç½®
        save_config()
        
        # æ£€æŸ¥FFmpegçŠ¶æ€
        ffmpeg_status = "å¯ç”¨" if check_ffmpeg() else "ä¸å¯ç”¨"
        
        # æ˜¾ç¤ºçŠ¶æ€æç¤º
        message = f"éŸ³é¢‘æºå·²åˆ‡æ¢åˆ°: {source_name}\n\n"
        
        if audio_source == 'system':
            message += f"ç³»ç»ŸéŸ³é¢‘æ•è·æ–¹å¼:\n"
            message += f"â€¢ FFmpegç›´æ¥æ•è·: {ffmpeg_status}\n"
            message += f"â€¢ è™šæ‹ŸéŸ³é¢‘è®¾å¤‡: éœ€è¦VB-CABLEç­‰\n"
            message += f"â€¢ ç«‹ä½“å£°æ··éŸ³: éœ€è¦æ‰‹åŠ¨å¯ç”¨\n\n"
            
            if not check_ffmpeg():
                message += "âš ï¸ å»ºè®®å®‰è£…FFmpegä»¥è·å¾—æœ€ä½³ä½“éªŒ\n\n"
        
        message += f"å¿«æ·é”®:\n"
        message += f"Alt+A: åˆ‡æ¢éŸ³é¢‘æº\n"
        message += f"Alt+D: é€‰æ‹©ç³»ç»ŸéŸ³é¢‘è®¾å¤‡\n"
        message += f"Alt+P: æš‚åœ/æ¢å¤ç›‘å¬\n"
        message += f"Alt+S: æ‰“å¼€è®¾ç½®\n"
        message += f"Alt+T: åˆ‡æ¢é¢œè‰²æ¨¡å¼\n\n"
        message += f"æ³¨æ„: éœ€è¦é‡å¯ç¨‹åºä»¥åº”ç”¨æ–°çš„éŸ³é¢‘æºè®¾ç½®"
        
        wx.MessageBox(message, "éŸ³é¢‘æºåˆ‡æ¢", wx.OK | wx.ICON_INFORMATION)

    def show_audio_device_dialog(self):
        """æ˜¾ç¤ºéŸ³é¢‘è®¾å¤‡é€‰æ‹©å¯¹è¯æ¡†"""
        global current_system_device
        
        # æ£€æŸ¥FFmpegæ˜¯å¦å¯ç”¨
        ffmpeg_available = check_ffmpeg()
        
        # è·å–ä¸åŒç±»å‹çš„éŸ³é¢‘è®¾å¤‡
        virtual_devices = get_virtual_audio_devices()
        all_devices = get_system_audio_devices()
        
        if not all_devices and not ffmpeg_available:
            wx.MessageBox("æœªæ£€æµ‹åˆ°å¯ç”¨çš„éŸ³é¢‘è®¾å¤‡ï¼Œä¸”FFmpegä¸å¯ç”¨", "é”™è¯¯", wx.OK | wx.ICON_ERROR)
            return
        
        # æ„å»ºè®¾å¤‡åˆ—è¡¨
        device_list = []
        device_indices = []
        device_types = []  # è®°å½•è®¾å¤‡ç±»å‹
        
        if ffmpeg_available:
            device_list.append("=== FFmpegç³»ç»ŸéŸ³é¢‘æ•è·ï¼ˆæ¨èï¼‰ ===")
            device_indices.append(None)
            device_types.append('header')
            
            device_list.append("ğŸµ ç³»ç»ŸéŸ³é¢‘è¾“å‡ºï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼‰")
            device_indices.append(-1)  # ç‰¹æ®Šç´¢å¼•è¡¨ç¤ºä½¿ç”¨FFmpegé»˜è®¤
            device_types.append('ffmpeg')
            
            # æ·»åŠ FFmpegæ£€æµ‹åˆ°çš„è®¾å¤‡
            ffmpeg_devices = get_windows_audio_devices()
            for i, dev in enumerate(ffmpeg_devices):
                device_list.append(f"ğŸµ {dev['name']} (FFmpeg)")
                device_indices.append(i)
                device_types.append('ffmpeg')
        
        if virtual_devices:
            device_list.append("=== è™šæ‹ŸéŸ³é¢‘è®¾å¤‡ ===")
            device_indices.append(None)
            device_types.append('header')
            
            for dev in virtual_devices:
                device_list.append(f"ğŸ”Œ {dev['name']} (ç´¢å¼•: {dev['index']})")
                device_indices.append(dev['index'])
                device_types.append('virtual')
        
        device_list.append("=== æ‰€æœ‰è¾“å…¥è®¾å¤‡ ===")
        device_indices.append(None)
        device_types.append('header')
        
        for dev in all_devices:
            if dev['type'] == 'input':
                device_list.append(f"ğŸ¤ {dev['name']} (ç´¢å¼•: {dev['index']})")
                device_indices.append(dev['index'])
                device_types.append('regular')
        
        # åˆ›å»ºè®¾å¤‡é€‰æ‹©å¯¹è¯æ¡†
        dialog = wx.SingleChoiceDialog(
            self,
            "è¯·é€‰æ‹©è¦ç›‘å¬çš„éŸ³é¢‘è®¾å¤‡:\n\n"
            "ğŸµ FFmpegç³»ç»ŸéŸ³é¢‘ - ç›´æ¥æ•è·ç³»ç»Ÿè¾“å‡ºï¼ˆæ¨èï¼‰\n"
            "ğŸ”Œ è™šæ‹ŸéŸ³é¢‘è®¾å¤‡ - VB-CABLEç­‰è™šæ‹Ÿçº¿ç¼†\n"
            "ğŸ¤ æ™®é€šè¾“å…¥è®¾å¤‡ - éº¦å…‹é£ç­‰\n\n"
            f"FFmpegçŠ¶æ€: {'âœ… å¯ç”¨' if ffmpeg_available else 'âŒ ä¸å¯ç”¨'}",
            "é€‰æ‹©éŸ³é¢‘è®¾å¤‡",
            device_list
        )
        
        if dialog.ShowModal() == wx.ID_OK:
            selection = dialog.GetSelection()
            selected_index = device_indices[selection]
            selected_type = device_types[selection]
            
            if selected_index is not None and selected_type != 'header':
                current_system_device = selected_index
                
                if selected_type == 'ffmpeg':
                    if selected_index == -1:
                        message = "å·²é€‰æ‹©FFmpegç³»ç»ŸéŸ³é¢‘æ•è·ï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼‰\n\n"
                        message += "è¿™å°†ç›´æ¥æ•è·ç³»ç»ŸéŸ³é¢‘è¾“å‡ºï¼Œæ— éœ€é¢å¤–é…ç½®ã€‚\n\n"
                    else:
                        ffmpeg_devices = get_windows_audio_devices()
                        if selected_index < len(ffmpeg_devices):
                            device_name = ffmpeg_devices[selected_index]['name']
                            message = f"å·²é€‰æ‹©FFmpegè®¾å¤‡:\n{device_name}\n\n"
                    
                    message += "ä¼˜ç‚¹:\nâ€¢ ç›´æ¥æ•è·ç³»ç»ŸéŸ³é¢‘\nâ€¢ æ— éœ€é¢å¤–è½¯ä»¶\nâ€¢ éŸ³è´¨ä¼˜ç§€\n\n"
                    
                elif selected_type == 'virtual':
                    selected_device = next((dev for dev in all_devices if dev['index'] == selected_index), None)
                    if selected_device:
                        message = f"å·²é€‰æ‹©è™šæ‹ŸéŸ³é¢‘è®¾å¤‡:\n{selected_device['name']}\n\n"
                        message += "ä½¿ç”¨è¯´æ˜:\n1. å°†ç³»ç»ŸéŸ³é¢‘è¾“å‡ºè®¾ç½®ä¸ºæ­¤è™šæ‹Ÿè®¾å¤‡\n2. æ’­æ”¾éŸ³é¢‘å³å¯æ•è·\n\n"
                
                else:
                    selected_device = next((dev for dev in all_devices if dev['index'] == selected_index), None)
                    if selected_device:
                        message = f"å·²é€‰æ‹©è¾“å…¥è®¾å¤‡:\n{selected_device['name']}\n\n"
                
                message += "é‡å¯ç¨‹åºä»¥åº”ç”¨æ–°è®¾ç½®"
                wx.MessageBox(message, "è®¾å¤‡é€‰æ‹©å®Œæˆ", wx.OK | wx.ICON_INFORMATION)
                
                # ä¿å­˜é…ç½®
                save_config()
                
                print(f"å·²é€‰æ‹©éŸ³é¢‘è®¾å¤‡: ç´¢å¼•={current_system_device}, ç±»å‹={selected_type}")
        
        dialog.Destroy()

    def toggle_color_mode(self):
        """åˆ‡æ¢é»‘ç™½é¢œè‰²æ¨¡å¼"""
        self.is_dark_mode = not self.is_dark_mode
        # è®¾ç½®æ–‡å­—é¢œè‰²å¹¶åº”ç”¨
        self.text_color = wx.Colour(255, 255, 255) if self.is_dark_mode else wx.Colour(0, 0, 0)
        #attr = wx.TextAttr(self.text_color)
        # self.chinese_text_box.SetDefaultStyle(attr)
        # self.target_language_text_box.SetDefaultStyle(attr)
        # åº”ç”¨æ–°çš„èƒŒæ™¯è®¾ç½®
        #
        if self.is_dark_mode:
            self.set_panel_alpha(255)  # é‡æ–°åº”ç”¨å½“å‰é€æ˜åº¦è®¾ç½®
            self.panel.SetBackgroundColour(wx.Colour(0, 0, 0, 0))
        else:
            self.set_panel_alpha(0)  # é‡æ–°åº”ç”¨å½“å‰é€æ˜åº¦è®¾ç½®
            self.panel.SetBackgroundColour(wx.Colour(255, 255, 255, 0))

        # ç«‹å³åˆ·æ–°æ–‡æœ¬æ˜¾ç¤º
        self.chinese_text_box.Refresh()
        self.target_language_text_box.Refresh()
        # æ›´æ–°çª—å£é€æ˜åº¦è®¾ç½®ï¼ˆä»…Windowsï¼‰
        if wx.Platform == "__WXMSW__":
            hwnd = self.GetHandle()
            ctypes.windll.user32.SetLayeredWindowAttributes(
                hwnd,
                0,
                self.bg_alpha,  # ä½¿ç”¨å®é™…çš„alphaå€¼
                0x02  # LWA_ALPHA
            )

        # æ›´æ–°UIç»„ä»¶
        self.chinese_text_box.Freeze()
        self.target_language_text_box.Freeze()

        try:
            # æ›´æ–°èƒŒæ™¯è‰²å’Œæ–‡å­—é¢œè‰²
            self.chinese_text_box.SetBackgroundColour(self.bg_color)
            self.target_language_text_box.SetBackgroundColour(self.bg_color)

            # å¼ºåˆ¶åº”ç”¨æ–°çš„æ–‡å­—é¢œè‰²
            attr = wx.TextAttr(self.text_color)
            attr.SetLineSpacing(14)  # è®¾ç½®è¡Œé—´è·
            self.chinese_text_box.SetDefaultStyle(attr)
            self.target_language_text_box.SetDefaultStyle(attr)
            # é‡å†™å½“å‰æ–‡æœ¬ä»¥ç«‹å³ç”Ÿæ•ˆ
            self.chinese_text_box.SetValue(self.chinese_text_box.GetValue())
            self.target_language_text_box.SetValue(self.target_language_text_box.GetValue())

            # å¼ºåˆ¶åˆ·æ–°æ˜¾ç¤º
            self.chinese_text_box.Refresh()
            self.target_language_text_box.Refresh()
            self.panel.Layout()
            self.Refresh()

            # æ›´æ–°çª—å£é€æ˜åº¦è®¾ç½®ï¼ˆä»…Windowsï¼‰
            if wx.Platform == "__WXMSW__":
                hwnd = self.GetHandle()
                ctypes.windll.user32.SetLayeredWindowAttributes(
                    hwnd,
                    0,
                    self.panel_alpha,
                    0x02  # LWA_ALPHA
                )
        except Exception as e:
            print(f"åˆ‡æ¢é¢œè‰²æ¨¡å¼æ—¶å‡ºé”™: {e}")
        finally:
            self.chinese_text_box.Thaw()
            self.target_language_text_box.Thaw()

        # Try to set theme for RichTextCtrl (Windows specific) - Moved outside finally block
        if wx.Platform == "__WXMSW__":
            try:
                chinese_hwnd = self.chinese_text_box.GetHandle()
                target_hwnd = self.target_language_text_box.GetHandle()
                if self.is_dark_mode:
                    # Try applying explicit dark theme identifier
                    ctypes.windll.uxtheme.SetWindowTheme(chinese_hwnd, ctypes.c_wchar_p("DarkMode_Explorer"), None)
                    ctypes.windll.uxtheme.SetWindowTheme(target_hwnd, ctypes.c_wchar_p("DarkMode_Explorer"), None)
                else:
                    # Remove theme to revert to default
                    ctypes.windll.uxtheme.SetWindowTheme(chinese_hwnd, None, None)
                    ctypes.windll.uxtheme.SetWindowTheme(target_hwnd, None, None)
                # Refresh the controls after changing the theme
                self.chinese_text_box.Refresh()
                self.target_language_text_box.Refresh()

                # Attempt to set dark mode for the title bar (Windows 10 build 17763+ / Windows 11)
                try:
                    frame_hwnd = self.GetHandle()
                    # DWMWA_USE_IMMERSIVE_DARK_MODE = 20 (Win 11 22000+) or 19 (Older Win 10/11)
                    # We'll try 20 first, might need refinement based on OS version checks
                    attribute_value = 20 
                    value = ctypes.c_int(1) if self.is_dark_mode else ctypes.c_int(0)
                    ctypes.windll.dwmapi.DwmSetWindowAttribute(frame_hwnd, attribute_value, ctypes.byref(value), ctypes.sizeof(value))
                except Exception as dwm_error:
                    # Fallback for older systems or if attribute 19 is needed
                    try:
                        attribute_value = 19
                        value = ctypes.c_int(1) if self.is_dark_mode else ctypes.c_int(0)
                        ctypes.windll.dwmapi.DwmSetWindowAttribute(frame_hwnd, attribute_value, ctypes.byref(value), ctypes.sizeof(value))
                    except Exception as dwm_error_fallback:
                         print(f"Error setting dark title bar (DWM): {dwm_error} / {dwm_error_fallback}")


            except Exception as theme_error:
                print(f"Error setting window theme: {theme_error}")

    def update_text(self, asr_result: TranscriptionResult, translation_result: TranslationResult):
        """æ›´æ–°æ–‡æœ¬æ¡†å†…å®¹"""

        def process_result(result, text_buffer, text_box):
            is_new_sentence = False
            fixed_text = ''
            unfixed_text = ''

            if result is not None:  # æ£€æŸ¥ç»“æœæ˜¯å¦ä¸ºç©º
                for word in result.words:
                    if word.fixed:
                        fixed_text += word.text
                    else:
                        unfixed_text += word.text

                # Update buffers with new text
                text_buffer[-1] = [fixed_text, unfixed_text]

                if result.is_sentence_end:
                    text_buffer.append(['', ''])

            fixed_text = ''
            unfixed_text = ''
            if result is not None and result.stash is not None:  # æ£€æŸ¥ç»“æœå’Œstashæ˜¯å¦ä¸ºç©º
                for word in result.stash.words:
                    if word['fixed']:
                        fixed_text += word.text
                    else:
                        unfixed_text += word.text
                text_buffer[-1] = [fixed_text, unfixed_text]

            # Clear and update text box
            text_box.Clear()

            attr = rt.RichTextAttr()
            attr.SetAlignment(wx.TEXT_ALIGNMENT_LEFT)  #å·¦å¯¹é½
            attr.SetLineSpacing(14)  # è®¾ç½®è¡Œé—´è·
            #attr.SetTextColour(self.text_color)
            text_box.SetDefaultStyle(attr)

            # Write all lines except the last one in black
            normal_font = wx.Font(14, wx.FONTFAMILY_DEFAULT, wx.FONTSTYLE_NORMAL,
                                 wx.FONTWEIGHT_NORMAL)
            text_box.BeginFont(normal_font)
            text_box.BeginTextColour(wx.BLACK)
            if self.is_dark_mode:
                text_box.BeginTextColour(wx.WHITE)

            if len(text_buffer) > 1:
                text_box.WriteText(
                    ''.join([x[0] + x[1] for x in text_buffer[:-1]]))
                    #'\n'.join([x[0] + x[1] for x in text_buffer[:-1]]) + '\n')
                    #''.join([x[0] + x[1] for x in text_buffer[:-1]]) + '\n')

            # Write the last line in blue with larger font
            large_font = wx.Font(14, wx.FONTFAMILY_DEFAULT, wx.FONTSTYLE_NORMAL,
                                 wx.FONTWEIGHT_BOLD)
            text_box.BeginFont(large_font)
            text_box.BeginTextColour(wx.BLACK)
            if self.is_dark_mode:
                text_box.BeginTextColour(wx.WHITE)
            text_box.WriteText(text_buffer[-1][0] + text_buffer[-1][1])
            text_box.EndTextColour()
            text_box.EndFont()

            # Auto-scroll to the bottom of the text boxes
            text_box.ShowPosition(text_box.GetLastPosition() - 2)

        if asr_result:
            process_result(asr_result, self.chinese_text_buffer, self.chinese_text_box)

        if translation_result:
            translation = translation_result.get_translation('zh')
            if translation:
                process_result(translation, self.target_language_text_buffer, self.target_language_text_box)


if __name__ == '__main__':
    try:
        # åŠ è½½é…ç½®
        load_config()
        
        # åˆå§‹åŒ– Dashscope API key
        init_dashscope_api_key()
        
        # è®¾ç½®DPIæ„ŸçŸ¥
        ctypes.windll.shcore.SetProcessDpiAwareness(2) 
        
        # æ˜¾ç¤ºå¯åŠ¨ä¿¡æ¯
        print("=" * 50)
        print("ğŸµ Gummyç¿»è¯‘å™¨å¯åŠ¨")
        print("=" * 50)
        print(f"é»˜è®¤éŸ³é¢‘æº: {'ğŸ¤ éº¦å…‹é£' if audio_source == 'microphone' else 'ğŸ”Š ç³»ç»ŸéŸ³é¢‘'}")
        print(f"TTSçŠ¶æ€: {'å¯ç”¨' if enable_tts else 'ç¦ç”¨'}")
        ffmpeg_available = check_ffmpeg()
        print(f"FFmpegçŠ¶æ€: {'å¯ç”¨' if ffmpeg_available else 'ä¸å¯ç”¨'}")
        print("=" * 50)
        
        # å¦‚æœé€‰æ‹©ç³»ç»ŸéŸ³é¢‘ï¼Œæ£€æŸ¥å¯ç”¨çš„æ•è·æ–¹æ³•
        if audio_source == 'system':
            sounddevice_available = SOUNDDEVICE_AVAILABLE
            
            if ffmpeg_available:
                # FFmpegå¯ç”¨ï¼Œç›´æ¥å¯åŠ¨
                print(f"âœ… ä½¿ç”¨FFmpegè¿›è¡Œç³»ç»ŸéŸ³é¢‘æ•è·")
            elif sounddevice_available:
                # FFmpegä¸å¯ç”¨ï¼Œä½†æœ‰Sounddeviceï¼Œæç¤ºå¹¶ç»§ç»­
                print(f"â„¹ï¸  FFmpegä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨Sounddeviceä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ")
                print(f"ğŸ’¡ æç¤ºï¼šå®‰è£…FFmpegå¯è·å¾—æ›´å¥½çš„å…¼å®¹æ€§")
            else:
                # ä¸¤ç§æ–¹æ³•éƒ½ä¸å¯ç”¨ï¼Œéœ€è¦ç”¨æˆ·ç¡®è®¤
                print(f"âš ï¸  ç³»ç»ŸéŸ³é¢‘æ•è·ç»„ä»¶ä¸å¯ç”¨!")
                print(f"   FFmpeg: âŒ ä¸å¯ç”¨")
                print(f"   Sounddevice: âŒ ä¸å¯ç”¨")
                print(f"\nå»ºè®®è§£å†³æ–¹æ¡ˆ:")
                print(f"1. å®‰è£…FFmpeg: winget install FFmpeg")
                print(f"2. å®‰è£…Pythonåº“: pip install sounddevice numpy")
                print(f"3. å®‰è£…è™šæ‹ŸéŸ³é¢‘è®¾å¤‡: VB-CABLE, VoiceMeeterç­‰")
                print(f"4. åˆ‡æ¢åˆ°éº¦å…‹é£æ¨¡å¼")
                
                continue_choice = input("\næ˜¯å¦ä»è¦ç»§ç»­å¯åŠ¨ç¨‹åºï¼Ÿ(y/n): ").strip().lower()
                if continue_choice not in ['y', 'yes', 'æ˜¯']:
                    print("ç¨‹åºé€€å‡º")
                    exit(0)
        
        print(f"\nå¿«æ·é”®:")
        print(f"  Alt+A: åˆ‡æ¢éŸ³é¢‘æºï¼ˆéº¦å…‹é£/ç³»ç»ŸéŸ³é¢‘ï¼‰")
        print(f"  Alt+D: é€‰æ‹©ç³»ç»ŸéŸ³é¢‘è®¾å¤‡")
        print(f"  Alt+S: åˆ‡æ¢TTS")
        print(f"  Alt+T: åˆ‡æ¢é¢œè‰²æ¨¡å¼")
        print(f"  Alt+P: æ‰“å¼€è®¾ç½®")
        print(f"  Ctrl+H: åˆ‡æ¢æ ‡é¢˜æ ")
        print()
        
        asr_thread = threading.Thread(target=gummyAsrTask, daemon=True)
        asr_thread.start()
        tts_thread = threading.Thread(target=cosyvoiceTtsTask, daemon=True)
        tts_thread.start()
        
        app = wx.App(False)
        frame = FloatingSubtitleWindow()
        app.MainLoop()
    except KeyboardInterrupt:
        print("ç¨‹åºæ­£åœ¨é€€å‡º...")
    finally:
        # æ¸…ç†èµ„æº
        stop_ffmpeg_audio_capture() 
        stop_sounddevice_capture()
        if 'audio_stream' in globals() and audio_stream is not None:
            audio_stream.stop_stream()
            audio_stream.close()
        if 'mic' in globals() and mic is not None:
            mic.terminate()
        
        # ä¿å­˜é…ç½®
        save_config()
