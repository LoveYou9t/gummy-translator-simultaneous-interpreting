#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿéº¦å…‹é£æµ‹è¯•è„šæœ¬
ä½¿ç”¨éº¦å…‹é£å½•éŸ³æµ‹è¯•ASRåŠŸèƒ½
"""

import os
import sys
import time
import threading
import queue

# ç¡®ä¿èƒ½å¤Ÿå¯¼å…¥ä¸»ç¨‹åºçš„æ¨¡å—
sys.path.insert(0, os.path.dirname(__file__))

import pyaudio
import dashscope
from dashscope.audio.asr import *
from gummy_translator import (
    load_config, init_dashscope_api_key, check_api_status,
    config, enable_api_calls, target_language
)

def test_microphone_asr():
    """ä½¿ç”¨éº¦å…‹é£æµ‹è¯•ASR"""
    print("\n" + "=" * 60)
    print("ğŸ¤ éº¦å…‹é£ASRæµ‹è¯•")
    print("=" * 60)
    
    # æ£€æŸ¥APIçŠ¶æ€
    check_api_status()
    
    if not enable_api_calls:
        print("âŒ APIè°ƒç”¨è¢«ç¦ç”¨ï¼Œæ— æ³•è¿›è¡Œæµ‹è¯•")
        return False
    
    print("ğŸ¤ è¯·å‡†å¤‡å¯¹ç€éº¦å…‹é£è¯´è¯...")
    print("   æµ‹è¯•å°†æŒç»­10ç§’é’Ÿ")
    print("   å»ºè®®è¯´ä¸€äº›ç®€å•çš„ä¸­æ–‡æˆ–è‹±æ–‡å¥å­")
    
    input("æŒ‰å›è½¦é”®å¼€å§‹æµ‹è¯•...")
    
    mic = None
    audio_stream = None
    
    class TestCallback(TranslationRecognizerCallback):
        def __init__(self):
            super().__init__()
            self.events_received = 0
            self.frames_sent = 0
            
        def on_open(self):
            nonlocal mic, audio_stream
            print("âœ… ASRè¿æ¥å·²å»ºç«‹ï¼Œå¼€å§‹å½•éŸ³...")
            
            # åˆå§‹åŒ–éº¦å…‹é£
            mic = pyaudio.PyAudio()
            audio_stream = mic.open(
                format=pyaudio.paInt16,
                channels=1,
                rate=16000,
                input=True,
                frames_per_buffer=3200
            )
            
        def on_close(self):
            nonlocal mic, audio_stream
            print("ğŸ”š ASRè¿æ¥å·²å…³é—­")
            
            # æ¸…ç†éŸ³é¢‘èµ„æº
            if audio_stream:
                audio_stream.stop_stream()
                audio_stream.close()
                audio_stream = None
            if mic:
                mic.terminate() 
                mic = None
            
        def on_event(self, request_id, transcription_result, translation_result, usage):
            self.events_received += 1
            print(f"\nğŸ“¨ ASRäº‹ä»¶ #{self.events_received}:")
            
            if transcription_result:
                words = [w.text for w in transcription_result.words if w.fixed]
                if words:
                    print(f"   ğŸ¯ è½¬å½•: {''.join(words)}")
                
                # æ˜¾ç¤ºæ‰€æœ‰è¯ï¼ˆåŒ…æ‹¬ä¸´æ—¶çš„ï¼‰
                all_words = [w.text for w in transcription_result.words]
                if all_words:
                    print(f"   ğŸ“ å®Œæ•´: {''.join(all_words)}")
                    
            if translation_result:
                trans = translation_result.get_translation(target_language)
                if trans:
                    words = [w.text for w in trans.words if w.fixed]
                    if words:
                        print(f"   ğŸŒ ç¿»è¯‘: {''.join(words)}")
    
    try:
        callback = TestCallback()
        asr_model = config.get('asr_model', 'gummy-realtime-v1')
        print(f"ä½¿ç”¨ASRæ¨¡å‹: {asr_model}")
        
        translator = TranslationRecognizerRealtime(
            model=asr_model,
            format='pcm',
            sample_rate=16000,
            transcription_enabled=True,
            translation_enabled=True,
            translation_target_languages=[target_language],
            callback=callback,
        )
        
        print("å¯åŠ¨ASR translator...")
        translator.start()
        
        # ç­‰å¾…è¿æ¥å»ºç«‹
        time.sleep(1)
        
        # å½•éŸ³å¹¶å‘é€éŸ³é¢‘æ•°æ®
        print("ğŸ”´ å½•éŸ³å¼€å§‹...")
        start_time = time.time()
        
        while time.time() - start_time < 10:  # å½•éŸ³10ç§’
            if audio_stream:
                try:
                    data = audio_stream.read(3200, exception_on_overflow=False)
                    translator.send_audio_frame(data)
                    callback.frames_sent += 1
                    
                    # è®¡ç®—éŸ³é‡
                    import struct
                    if len(data) >= 2:
                        samples = struct.unpack('<' + 'h' * (len(data) // 2), data)
                        rms = (sum(sample * sample for sample in samples) / len(samples)) ** 0.5
                        
                        # æ¯ç§’æ˜¾ç¤ºä¸€æ¬¡éŸ³é‡
                        if callback.frames_sent % 100 == 0:
                            print(f"â±ï¸  {time.time() - start_time:.1f}s - éŸ³é‡: {rms:.0f}")
                            
                except Exception as e:
                    print(f"å½•éŸ³é”™è¯¯: {e}")
                    break
        
        print("ğŸ”´ å½•éŸ³ç»“æŸ")
        
        # ç­‰å¾…æœ€åçš„å¤„ç†ç»“æœ
        print("ç­‰å¾…æœ€ç»ˆç»“æœ...")
        time.sleep(2)
        
        print("åœæ­¢ASR translator...")
        translator.stop()
        
        print(f"\næµ‹è¯•ç»“æœ:")
        print(f"  å½•éŸ³æ—¶é•¿: 10ç§’")
        print(f"  éŸ³é¢‘å¸§æ•°: {callback.frames_sent}")
        print(f"  ASRäº‹ä»¶: {callback.events_received}")
        
        if callback.events_received > 0:
            print("âœ… éº¦å…‹é£ASRæµ‹è¯•æˆåŠŸï¼")
            print("ğŸ’¡ è¿™è¯´æ˜ASRåŠŸèƒ½æ­£å¸¸ï¼Œé—®é¢˜å¯èƒ½åœ¨äºç³»ç»ŸéŸ³é¢‘æ•è·")
            return True
        else:
            print("âŒ éº¦å…‹é£ASRæµ‹è¯•å¤±è´¥ï¼šæœªæ”¶åˆ°ä»»ä½•äº‹ä»¶")
            print("å¯èƒ½çš„åŸå› :")
            print("  1. éº¦å…‹é£æ²¡æœ‰å£°éŸ³è¾“å…¥")
            print("  2. ASRæœåŠ¡é—®é¢˜")
            print("  3. éŸ³é¢‘æ ¼å¼é—®é¢˜")
            return False
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    print("ğŸ¤ éº¦å…‹é£ASRæµ‹è¯•å·¥å…·")
    print("=" * 40)
    
    # åŠ è½½é…ç½®
    print("åŠ è½½é…ç½®...")
    load_config()
    init_dashscope_api_key()
    
    # è¿è¡Œæµ‹è¯•
    test_microphone_asr()

if __name__ == '__main__':
    main()
